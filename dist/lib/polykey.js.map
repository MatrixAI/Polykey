{"version":3,"sources":["webpack://polykey/webpack/universalModuleDefinition","webpack://polykey/webpack/bootstrap","webpack://polykey/external \"path\"","webpack://polykey/external \"os\"","webpack://polykey/external \"fs\"","webpack://polykey/external \"readable-stream\"","webpack://polykey/./src/lib/Polykey.ts","webpack://polykey/external \"crypto\"","webpack://polykey/external \"@grpc/grpc-js\"","webpack://polykey/external \"../../proto/compiled/Git_grpc_pb\"","webpack://polykey/external \"../../proto/compiled/Git_pb\"","webpack://polykey/./src/lib/git/upload-pack/GitPktLine.ts","webpack://polykey/./src/lib/git/upload-pack/GitRefManager.ts","webpack://polykey/external \"pako\"","webpack://polykey/./src/lib/git/pack-objects/GitCommit.ts","webpack://polykey/./src/lib/git/pack-objects/GitObjectManager.ts","webpack://polykey/./src/lib/peers/PeerInfo.ts","webpack://polykey/external \"isomorphic-git\"","webpack://polykey/external \"encryptedfs\"","webpack://polykey/external \"virtualfs\"","webpack://polykey/./src/lib/agent/PolykeyClient.ts","webpack://polykey/external \"../../proto/js/Agent\"","webpack://polykey/./src/lib/keys/KeyManager.ts","webpack://polykey/external \"kbpgp\"","webpack://polykey/external \"util\"","webpack://polykey/./src/lib/peers/PeerManager.ts","webpack://polykey/./src/lib/git/GitFrontend.ts","webpack://polykey/./src/lib/git/GitBackend.ts","webpack://polykey/./src/lib/git/upload-pack/uploadPack.ts","webpack://polykey/./src/lib/git/upload-pack/GitPackedRefs.ts","webpack://polykey/./src/lib/git/side-band/GitSideBand.ts","webpack://polykey/external \"buffer\"","webpack://polykey/./src/lib/git/pack-objects/packObjects.ts","webpack://polykey/./src/lib/git/pack-objects/log.ts","webpack://polykey/./src/lib/git/pack-objects/GitObject.ts","webpack://polykey/./src/lib/git/pack-objects/shasum.ts","webpack://polykey/external \"sha.js/sha1\"","webpack://polykey/./src/lib/git/pack-objects/GitTree.ts","webpack://polykey/external \"sha.js\"","webpack://polykey/external \"../../proto/js/Peer\"","webpack://polykey/./src/lib/utils.ts","webpack://polykey/./src/lib/peers/MulticastBroadcaster.ts","webpack://polykey/external \"dgram\"","webpack://polykey/external \"events\"","webpack://polykey/external \"../../proto/js/Peer.js\"","webpack://polykey/./src/lib/vaults/VaultManager.ts","webpack://polykey/./src/lib/vaults/Vault.ts","webpack://polykey/external \"async-mutex\"","webpack://polykey/./src/lib/agent/PolykeyAgent.ts","webpack://polykey/external \"net\"","webpack://polykey/external \"process\"","webpack://polykey/external \"child_process\"","webpack://polykey/external \"configstore\""],"names":[],"mappings":"AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;AACD,O;QCVA;QACA;;QAEA;QACA;;QAEA;QACA;QACA;QACA;QACA;QACA;QACA;QACA;QACA;QACA;;QAEA;QACA;;QAEA;QACA;;QAEA;QACA;QACA;;;QAGA;QACA;;QAEA;QACA;;QAEA;QACA;QACA;QACA,0CAA0C,gCAAgC;QAC1E;QACA;;QAEA;QACA;QACA;QACA,wDAAwD,kBAAkB;QAC1E;QACA,iDAAiD,cAAc;QAC/D;;QAEA;QACA;QACA;QACA;QACA;QACA;QACA;QACA;QACA;QACA;QACA;QACA,yCAAyC,iCAAiC;QAC1E,gHAAgH,mBAAmB,EAAE;QACrI;QACA;;QAEA;QACA;QACA;QACA,2BAA2B,0BAA0B,EAAE;QACvD,iCAAiC,eAAe;QAChD;QACA;QACA;;QAEA;QACA,sDAAsD,+DAA+D;;QAErH;QACA;;;QAGA;QACA;;;;;;;AClFA,iC;;;;;;ACAA,+B;;;;;;ACAA,+B;;;;;;ACAA,4C;;;;;;;ACAa;AACb;AACA,4CAA4C;AAC5C;AACA,8CAA8C,cAAc;AAC5D,6BAA6B,mBAAO,CAAC,CAAI;AACzC,qCAAqC,mBAAO,CAAC,EAAmB;AAChE;AACA,sCAAsC,mBAAO,CAAC,EAAqB;AACnE;AACA,uCAAuC,mBAAO,CAAC,EAAuB;AACtE;AACA,uCAAuC,mBAAO,CAAC,EAAsB;AACrE;AACA,wCAAwC,mBAAO,CAAC,EAAuB;AACvE;AACA;AACA,iCAAiC,uBAAuB;AACxD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;AC3BA,mC;;;;;;ACAA,0C;;;;;;ACAA,6D;;;;;;ACAA,wD;;;;;;;ACAa;AACb;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,8CAA8C,cAAc;AAC5D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AC5Fa;AACb;AACA,4CAA4C;AAC5C;AACA,8CAA8C,cAAc;AAC5D;AACA,+BAA+B,mBAAO,CAAC,CAAM;AAC7C,wCAAwC,mBAAO,CAAC,EAAiB;AACjE;AACA;AACA,OAAO,IAAI;AACX,YAAY,IAAI;AAChB,iBAAiB,IAAI;AACrB,kBAAkB,IAAI;AACtB,oBAAoB,IAAI;AACxB,oBAAoB,IAAI;AACxB;AACA;AACA;AACA,8BAA8B,EAAE;AAChC,8BAA8B,EAAE;AAChC;AACA;AACA,8BAA8B;AAC9B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB,aAAa;AACb,SAAS;AACT;AACA;AACA;AACA,SAAS;AACT,KAAK;AACL;AACA;AACA;AACA,gDAAgD,OAAO,gBAAgB,mBAAmB;AAC1F;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oDAAoD,OAAO,GAAG,SAAS;AACvE,kDAAkD,OAAO,GAAG,SAAS;AACrE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4CAA4C;AAC5C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2CAA2C,GAAG;AAC9C;AACA;AACA;AACA;AACA;AACA,6EAA6E;AAC7E;AACA,mDAAmD,OAAO,GAAG,IAAI,IAAI,mBAAmB;AACxF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;AC5HA,iC;;;;;;;ACAa;AACb;AACA;AACA;AACA,8CAA8C,cAAc;AAC5D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iCAAiC,qBAAqB;AACtD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,8BAA8B,0BAA0B;AACxD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,+BAA+B,SAAS;AACxC;AACA;AACA,yEAAyE;AACzE;AACA;AACA;AACA;AACA;AACA;AACA,qCAAqC,EAAE;AACvC;AACA;AACA;AACA,6BAA6B,YAAY,IAAI,aAAa,IAAI,iBAAiB,GAAG,4CAA4C;AAC9H;AACA,gCAAgC,eAAe,IAAI,gBAAgB,IAAI,oBAAoB,GAAG,+CAA+C;AAC7I;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACtLa;AACb;AACA,4CAA4C;AAC5C;AACA,8CAA8C,cAAc;AAC5D,6BAA6B,mBAAO,CAAC,CAAI;AACzC,+BAA+B,mBAAO,CAAC,EAAM;AAC7C,+BAA+B,mBAAO,CAAC,CAAM;AAC7C,oCAAoC,mBAAO,CAAC,EAAa;AACzD;AACA;AACA;AACA;AACA,8CAA8C,OAAO,WAAW,gBAAgB,GAAG,aAAa;AAChG,kCAAkC,gBAAgB,GAAG,aAAa;AAClE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gEAAgE,OAAO,gBAAgB,SAAS;AAChG,sCAAsC,OAAO;AAC7C;AACA;AACA,+CAA+C,2BAA2B;AAC1E,sDAAsD,SAAS;AAC/D;AACA;AACA;AACA;AACA;AACA;AACA,kDAAkD,OAAO,YAAY,mBAAmB;AACxF;AACA,0DAA0D,IAAI;AAC9D;AACA;AACA;AACA;AACA,+CAA+C,IAAI;AACnD;AACA;AACA,oBAAoB;AACpB;AACA;AACA;AACA,oBAAoB;AACpB;AACA,aAAa,eAAe,+BAA+B,cAAc;AACzE;AACA,oBAAoB;AACpB;AACA;AACA;;;;;;;;AC/Da;AACb,8CAA8C,cAAc;AAC5D;AACA;AACA;AACA;AACA;AACA;AACA;AACA,+DAA+D,QAAQ,GAAG,UAAU;AACpF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gDAAgD,QAAQ,GAAG,UAAU;AACrE;AACA;AACA,kBAAkB,QAAQ,GAAG,UAAU;AACvC;AACA;AACA;AACA;AACA,cAAc,QAAQ,GAAG,UAAU;AACnC;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;;;;;;;AClEA,2C;;;;;;ACAA,wC;;;;;;ACAA,sC;;;;;;;ACAa;AACb,8CAA8C,cAAc;AAC5D,gBAAgB,mBAAO,CAAC,EAAyB;AACjD,OAAO,4lCAA4lC;AACnmC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA,iBAAiB;AACjB;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA,mBAAmB,mBAAmB;AACtC;AACA,uBAAuB,QAAQ;AAC/B,yDAAyD,MAAM;AAC/D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uEAAuE,aAAa;AACpF;AACA;AACA;AACA;AACA;AACA,eAAe,aAAa;AAC5B;AACA;AACA;AACA;AACA,6DAA6D,iCAAiC;AAC9F;AACA;AACA;AACA;AACA;AACA,eAAe,aAAa;AAC5B;AACA;AACA;AACA;AACA,+DAA+D,eAAe;AAC9E;AACA;AACA;AACA;AACA;AACA,eAAe,QAAQ;AACvB;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wDAAwD,sBAAsB;AAC9E;AACA;AACA;AACA;AACA;AACA,eAAe,aAAa;AAC5B;AACA;AACA;AACA;AACA,wDAAwD,UAAU;AAClE;AACA;AACA;AACA;AACA;AACA,eAAe,aAAa;AAC5B;AACA;AACA;AACA;AACA,wDAAwD;AACxD;AACA;AACA;AACA;AACA;AACA,eAAe,WAAW;AAC1B;AACA;AACA;AACA;AACA,qDAAqD,UAAU;AAC/D;AACA;AACA;AACA;AACA;AACA,eAAe,aAAa;AAC5B;AACA;AACA;AACA;AACA,gEAAgE,oBAAoB;AACpF;AACA;AACA;AACA;AACA;AACA,eAAe,wBAAwB;AACvC,gBAAgB;AAChB;AACA;AACA;AACA;AACA;AACA;AACA,uDAAuD,uCAAuC;AAC9F;AACA;AACA;AACA;AACA;AACA,eAAe,gBAAgB;AAC/B;AACA;AACA;AACA;AACA,yDAAyD,0BAA0B;AACnF;AACA;AACA;AACA;AACA;AACA,eAAe,WAAW;AAC1B;AACA;AACA;AACA;AACA,0DAA0D,0BAA0B;AACpF;AACA;AACA;AACA;AACA;AACA,eAAe,gBAAgB;AAC/B;AACA;AACA;AACA;AACA,0DAA0D,uCAAuC;AACjG;AACA;AACA;AACA;AACA;AACA,eAAe,gBAAgB;AAC/B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,aAAa;AAC5B;AACA;AACA;AACA;AACA,uDAAuD,YAAY;AACnE;AACA;AACA;AACA;AACA;AACA,eAAe,aAAa;AAC5B;AACA;AACA;AACA;AACA,2DAA2D,YAAY;AACvE;AACA;AACA;AACA;AACA;AACA,eAAe,aAAa;AAC5B;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0DAA0D,YAAY;AACtE;AACA;AACA;AACA;AACA;AACA,eAAe,cAAc;AAC7B;AACA;AACA;AACA;AACA;AACA;AACA,yDAAyD,4CAA4C;AACrG;AACA;AACA,yDAAyD,+CAA+C;AACxG;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,aAAa;AAC5B;AACA;AACA;AACA;AACA,4DAA4D,wBAAwB;AACpF;AACA;AACA;AACA;AACA;AACA,eAAe,aAAa;AAC5B;AACA;AACA;AACA;AACA,wDAAwD,wBAAwB;AAChF;AACA;AACA;AACA;AACA;AACA,eAAe,SAAS;AACxB;AACA;AACA;AACA;AACA;AACA;AACA,yDAAyD,4CAA4C;AACrG;AACA;AACA,yDAAyD,+CAA+C;AACxG;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,aAAa;AAC5B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;AC/UA,iD;;;;;;;ACAa;AACb;AACA,4CAA4C;AAC5C;AACA,8CAA8C,cAAc;AAC5D,6BAA6B,mBAAO,CAAC,CAAI;AACzC,6BAA6B,mBAAO,CAAC,CAAI;AACzC,+BAA+B,mBAAO,CAAC,CAAM;AAC7C,gCAAgC,mBAAO,CAAC,EAAO;AAC/C,iCAAiC,mBAAO,CAAC,CAAQ;AACjD,eAAe,mBAAO,CAAC,EAAM;AAC7B;AACA,iCAAiC,uBAAuB;AACxD,+BAA+B;AAC/B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB;AACxB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yDAAyD,kBAAkB;AAC3E;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6DAA6D,kCAAkC;AAC/F,uBAAuB,KAAK,IAAI,MAAM;AACtC;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA,+DAA+D;AAC/D;AACA,8FAA8F;AAC9F;AACA,+FAA+F,yBAAyB;AACxH;AACA,yBAAyB;AACzB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qGAAqG,qBAAqB;AAC1H,2EAA2E,sBAAsB;AACjG;AACA,wEAAwE,yBAAyB;AACjG;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4DAA4D,KAAK;AACjE;AACA;AACA,qEAAqE,kBAAkB;AACvF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4DAA4D,KAAK;AACjE;AACA;AACA,gFAAgF,kBAAkB;AAClG;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qGAAqG,qBAAqB;AAC1H;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qGAAqG,sBAAsB;AAC3H;AACA,wEAAwE,aAAa;AACrF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,8BAA8B,SAAS;AACvC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;ACrpBA,kC;;;;;;ACAA,iC;;;;;;;ACAa;AACb;AACA,4CAA4C;AAC5C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,8CAA8C,cAAc;AAC5D,6BAA6B,mBAAO,CAAC,CAAI;AACzC,+BAA+B,mBAAO,CAAC,CAAM;AAC7C,0BAA0B,mBAAO,CAAC,CAAe;AACjD,sCAAsC,mBAAO,CAAC,EAAoB;AAClE,qCAAqC,mBAAO,CAAC,EAAmB;AAChE,eAAe,mBAAO,CAAC,EAAwB;AAC/C,gBAAgB,mBAAO,CAAC,EAAU;AAClC,gCAAgC,mBAAO,CAAC,EAAmB;AAC3D,+CAA+C,mBAAO,CAAC,EAA+B;AACtF,sBAAsB,mBAAO,CAAC,CAAqC;AACnE,iBAAiB,mBAAO,CAAC,CAAgC;AACzD;AACA;AACA;AACA,qEAAqE,QAAQ,GAAG,OAAO;AACvF;AACA;AACA;AACA;AACA;AACA;AACA;AACA,+CAA+C,YAAY;AAC3D;AACA,KAAK;AACL;AACA;AACA,iCAAiC,uBAAuB;AACxD;AACA,yBAAyB;AACzB;AACA;AACA,gDAAgD,kBAAkB;AAClE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA;AACA;AACA,yCAAyC,8DAA8D;AACvG;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA,aAAa;AACb,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,8EAA8E,qBAAqB;AACnG;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA,mBAAmB,mCAAmC;AACtD;AACA;AACA;AACA;AACA;;;;;;;;ACxQa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA,8CAA8C,cAAc;AAC5D,0BAA0B,mBAAO,CAAC,CAAe;AACjD,sBAAsB,mBAAO,CAAC,CAAqC;AACnE,iBAAiB,mBAAO,CAAC,CAAgC;AACzD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb,SAAS;AACT;AACA;AACA;;;;;;;;AChEa;AACb;AACA,4CAA4C;AAC5C;AACA,8CAA8C,cAAc;AAC5D,+BAA+B,mBAAO,CAAC,CAAM;AAC7C,0BAA0B,mBAAO,CAAC,CAAiB;AACnD,qCAAqC,mBAAO,CAAC,EAA0B;AACvE,sCAAsC,mBAAO,CAAC,EAAyB;AACvE,sCAAsC,mBAAO,CAAC,EAA4B;AAC1E;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uDAAuD,SAAS;AAChE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2DAA2D,SAAS;AACpE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA,iBAAiB;AACjB;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AC5Ea;AACb;AACA,4CAA4C;AAC5C;AACA,8CAA8C,cAAc;AAC5D,+BAA+B,mBAAO,CAAC,CAAM;AAC7C,qCAAqC,mBAAO,CAAC,CAAc;AAC3D,wCAAwC,mBAAO,CAAC,EAAiB;AACjE,oCAAoC,8BAA8B;AAClE;AACA;AACA;AACA;AACA,0BAA0B,IAAI,GAAG,MAAM;AACvC;AACA,sBAAsB,4BAA4B,GAAG,KAAK;AAC1D,mDAAmD,QAAQ;AAC3D;AACA;AACA;AACA;AACA,mDAAmD,MAAM,GAAG,IAAI,EAAE,KAAK;AACvE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6CAA6C,IAAI;AACjD;AACA,iCAAiC;AACjC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACrDa;AACb,8CAA8C,cAAc;AAC5D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4BAA4B;AAC5B;AACA;AACA;AACA;AACA;AACA;AACA,qCAAqC;AACrC,4CAA4C;AAC5C,4BAA4B;AAC5B;AACA;AACA;AACA;AACA;AACA;AACA,4BAA4B;AAC5B;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACvCa;AACb;AACA,4CAA4C;AAC5C;AACA,8CAA8C,cAAc;AAC5D;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA,iBAAiB,mBAAO,CAAC,EAAQ;AACjC,0BAA0B,mBAAO,CAAC,CAAiB;AACnD,qCAAqC,mBAAO,CAAC,CAA2B;AACxE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,cAAc;AACd;AACA;AACA;AACA,cAAc;AACd;AACA;AACA;AACA;;;;;;;ACrJA,mC;;;;;;;ACAa;AACb;AACA,4CAA4C;AAC5C;AACA,8CAA8C,cAAc;AAC5D,+BAA+B,mBAAO,CAAC,EAAM;AAC7C,+BAA+B,mBAAO,CAAC,CAAM;AAC7C,8BAA8B,mBAAO,CAAC,EAAO;AAC7C,kCAAkC,mBAAO,CAAC,EAAW;AACrD,iCAAiC,mBAAO,CAAC,EAAQ;AACjD,oCAAoC,mBAAO,CAAC,EAAa;AACzD,0BAA0B,mBAAO,CAAC,CAAiB;AACnD,2CAA2C,mBAAO,CAAC,EAAoB;AACvE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2BAA2B,oBAAoB;AAC/C;AACA;AACA;AACA;AACA,qBAAqB;AACrB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,YAAY;AACZ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa,eAAe;AAC5B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,aAAa,eAAe;AAC5B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACvKa;AACb;AACA,4CAA4C;AAC5C;AACA,8CAA8C,cAAc;AAC5D,aAAa,mBAAO,CAAC,CAAM;AAC3B,oCAAoC,mBAAO,CAAC,EAAa;AACzD,2CAA2C,mBAAO,CAAC,EAAoB;AACvE,wCAAwC,mBAAO,CAAC,EAA8B;AAC9E;AACA;AACA,aAAa,eAAe;AAC5B;AACA;AACA;AACA;AACA,sCAAsC,MAAM;AAC5C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACpFa;AACb;AACA,4CAA4C;AAC5C;AACA,8CAA8C,cAAc;AAC5D,iCAAiC,mBAAO,CAAC,EAAU;AACnD;AACA,iBAAiB,eAAe;AAChC,mDAAmD,KAAK,GAAG,6BAA6B;AACxF;AACA;AACA;AACA,iBAAiB,eAAe;AAChC,mDAAmD,KAAK,GAAG,6BAA6B;AACxF;AACA;AACA;AACA;AACA;AACA;AACA,mBAAmB,cAAc;AACjC;AACA;AACA;AACA,8DAA8D,IAAI,aAAa,IAAI;AACnF;AACA;AACA,mCAAmC;AACnC,kCAAkC;AAClC,uDAAuD;AACvD,6DAA6D;AAC7D;AACA;AACA;AACA,yDAAyD,OAAO,iBAAiB,aAAa;AAC9F;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AC1Ca;AACb;AACA,4CAA4C;AAC5C;AACA,8CAA8C,cAAc;AAC5D,+BAA+B,mBAAO,CAAC,EAAa;AACpD;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;ACZA,wC;;;;;;;ACAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,8CAA8C,cAAc;AAC5D;AACA;AACA;AACA;AACA;AACA;AACA,8EAA8E,OAAO;AACrF;AACA;AACA;AACA,8EAA8E,OAAO;AACrF;AACA;AACA;AACA,4BAA4B;AAC5B;AACA;AACA;AACA;AACA,uBAAuB,wBAAwB;AAC/C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uBAAuB;AACvB;AACA,wBAAwB;AACxB;AACA,wBAAwB;AACxB;AACA,wBAAwB;AACxB;AACA,wBAAwB;AACxB,uDAAuD,KAAK;AAC5D;AACA;AACA;AACA,8BAA8B;AAC9B;AACA,gDAAgD;AAChD;AACA,4BAA4B;AAC5B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,+CAA+C,WAAW,GAAG,WAAW,GAAG,UAAU,MAAM,WAAW;AACtG;AACA;AACA;AACA;AACA;AACA;AACA,mDAAmD,mBAAmB;AACtE;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;AClGA,mC;;;;;;ACAA,gD;;;;;;;ACAa;AACb,8CAA8C,cAAc;AAC5D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AC1Ba;AACb;AACA,4CAA4C;AAC5C;AACA;AACA,8CAA8C,cAAc;AAC5D,gCAAgC,mBAAO,CAAC,EAAO;AAC/C,iCAAiC,mBAAO,CAAC,CAAQ;AACjD,mCAAmC,mBAAO,CAAC,EAAY;AACvD,iBAAiB,mBAAO,CAAC,EAAQ;AACjC,kBAAkB,mBAAO,CAAC,EAA2B;AACrD,OAAO,oCAAoC;AAC3C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oDAAoD,gCAAgC;AACpF;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qBAAqB;AACrB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mBAAmB,4DAA4D;AAC/E;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2BAA2B,mCAAmC;AAC9D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;AC/IA,kC;;;;;;ACAA,mC;;;;;;ACAA,mD;;;;;;;ACAa;AACb;AACA,4CAA4C;AAC5C;AACA,8CAA8C,cAAc;AAC5D,6BAA6B,mBAAO,CAAC,CAAI;AACzC,+BAA+B,mBAAO,CAAC,CAAM;AAC7C,yCAAyC,mBAAO,CAAC,EAAgB;AACjE,gCAAgC,mBAAO,CAAC,EAAiB;AACzD,sBAAsB,mBAAO,CAAC,EAAa;AAC3C;AACA,iCAAiC,uBAAuB;AACxD;AACA;AACA;AACA;AACA;AACA,qDAAqD,kBAAkB;AACvE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4DAA4D,UAAU;AACtE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6CAA6C,kBAAkB;AAC/D;AACA;AACA;AACA;AACA,gEAAgE,UAAU;AAC1E;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gCAAgC;AAChC;AACA;AACA;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB;AACA,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2CAA2C,UAAU;AACrD;AACA;AACA;AACA;AACA,SAAS;AACT;AACA,sDAAsD,UAAU;AAChE;AACA;AACA;AACA,8DAA8D,UAAU;AACxE;AACA,iCAAiC,mBAAO,CAAC,EAAW;AACpD;AACA;AACA;AACA,iBAAiB,4BAA4B;AAC7C;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6CAA6C,kBAAkB;AAC/D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,4DAA4D,UAAU;AACtE;AACA;AACA,gEAAgE,UAAU;AAC1E;AACA;AACA;AACA,4DAA4D,UAAU;AACtE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACzNa;AACb;AACA,4CAA4C;AAC5C;AACA,8CAA8C,cAAc;AAC5D,6BAA6B,mBAAO,CAAC,CAAI;AACzC,+BAA+B,mBAAO,CAAC,CAAM;AAC7C,yCAAyC,mBAAO,CAAC,EAAgB;AACjE,sBAAsB,mBAAO,CAAC,EAAa;AAC3C,sBAAsB,mBAAO,CAAC,EAAa;AAC3C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iCAAiC,mBAAO,CAAC,EAAW;AACpD;AACA;AACA;AACA;AACA,4CAA4C,kBAAkB;AAC9D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mEAAmE;AACnE;AACA;AACA;AACA,oDAAoD,WAAW;AAC/D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mEAAmE;AACnE;AACA;AACA;AACA,uDAAuD,WAAW;AAClE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,sEAAsE;AACtE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2DAA2D,WAAW;AACtE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gBAAgB;AAChB,kBAAkB;AAClB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qBAAqB,8BAA8B;AACnD;AACA;AACA,aAAa;AACb;AACA;AACA,qBAAqB,8BAA8B;AACnD;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB;AACjB,aAAa;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iBAAiB,8BAA8B;AAC/C;AACA;AACA,SAAS;AACT;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA,uEAAuE,kBAAkB;AACzF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qBAAqB,8BAA8B;AACnD;AACA;AACA,aAAa;AACb;AACA;AACA;AACA,qBAAqB,8BAA8B;AACnD;AACA;AACA,aAAa;AACb;AACA;AACA,iBAAiB,8BAA8B;AAC/C;AACA;AACA;AACA,aAAa;AACb;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;AC1SA,wC;;;;;;;ACAa;AACb;AACA,4CAA4C;AAC5C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,8CAA8C,cAAc;AAC5D,6BAA6B,mBAAO,CAAC,CAAI;AACzC,6BAA6B,mBAAO,CAAC,CAAI;AACzC,8BAA8B,mBAAO,CAAC,EAAK;AAC3C,+BAA+B,mBAAO,CAAC,CAAM;AAC7C,kCAAkC,mBAAO,CAAC,EAAS;AACnD,wBAAwB,mBAAO,CAAC,EAAe;AAC/C,+BAA+B,mBAAO,CAAC,CAAY;AACnD,sCAAsC,mBAAO,CAAC,EAAa;AAC3D,wCAAwC,mBAAO,CAAC,EAAiB;AACjE,gBAAgB,mBAAO,CAAC,EAAyB;AACjD,OAAO,4lCAA4lC;AACnmC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6EAA6E,SAAS;AACtF;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6FAA6F,SAAS;AACtG;AACA;AACA;AACA;AACA,+DAA+D,SAAS;AACxE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA,uBAAuB,6BAA6B;AACpD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mEAAmE,uBAAuB;AAC1F;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qBAAqB;AACrB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,qDAAqD,iEAAiE;AACtH,iBAAiB;AACjB;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA,eAAe,aAAa;AAC5B;AACA;AACA;AACA;AACA,0EAA0E,SAAS;AACnF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA,sCAAsC,SAAS;AAC/C;AACA;AACA,sDAAsD,SAAS;AAC/D;AACA,eAAe,iCAAiC;AAChD;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA,eAAe,eAAe;AAC9B;AACA,oDAAoD,gCAAgC;AACpF;AACA;AACA,oDAAoD,2BAA2B;AAC/E;AACA;AACA;AACA;AACA;AACA;AACA,eAAe,sBAAsB;AACrC;AACA;AACA,gDAAgD,mBAAmB;AACnE;AACA;AACA;AACA;AACA,+CAA+C,WAAW;AAC1D;AACA;AACA,eAAe,UAAU;AACzB;AACA;AACA,6CAA6C,aAAa;AAC1D;AACA;AACA,eAAe,oBAAoB;AACnC;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA,eAAe,UAAU;AACzB;AACA;AACA,gDAAgD,aAAa;AAC7D;AACA;AACA;AACA;AACA;AACA,eAAe,uCAAuC;AACtD;AACA;AACA,+CAA+C,gBAAgB;AAC/D;AACA;AACA,eAAe,0BAA0B;AACzC;AACA;AACA,iDAAiD,WAAW;AAC5D;AACA;AACA,eAAe,0BAA0B;AACzC;AACA;AACA,kDAAkD,gBAAgB;AAClE;AACA;AACA,eAAe,uCAAuC;AACtD;AACA;AACA,kDAAkD,gBAAgB;AAClE;AACA;AACA;AACA;AACA;AACA;AACA;AACA,iDAAiD,aAAa;AAC9D;AACA;AACA,eAAe,YAAY;AAC3B;AACA;AACA,+CAA+C,mBAAmB;AAClE;AACA;AACA,eAAe,YAAY;AAC3B;AACA;AACA,mDAAmD,mBAAmB;AACtE;AACA;AACA;AACA;AACA;AACA,eAAe,YAAY;AAC3B;AACA;AACA;AACA,kDAAkD,cAAc;AAChE;AACA;AACA,eAAe,mDAAmD;AAClE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mDAAmD,mBAAmB;AACtE;AACA;AACA,eAAe,wBAAwB;AACvC;AACA;AACA;AACA,oDAAoD,mBAAmB;AACvE;AACA;AACA,eAAe,wBAAwB;AACvC;AACA;AACA;AACA,gDAAgD,iBAAiB;AACjE;AACA;AACA,eAAe,mDAAmD;AAClE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mDAAmD,mBAAmB;AACtE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gCAAgC,aAAa;AAC7C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,gCAAgC,aAAa;AAC7C;AACA;AACA;AACA;AACA;AACA,8DAA8D,kBAAkB;AAChF,8DAA8D,kBAAkB;AAChF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAAS;AACT;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;ACxeA,gC;;;;;;ACAA,oC;;;;;;ACAA,0C;;;;;;ACAA,wC","file":"polykey.js","sourcesContent":["(function webpackUniversalModuleDefinition(root, factory) {\n\tif(typeof exports === 'object' && typeof module === 'object')\n\t\tmodule.exports = factory();\n\telse if(typeof define === 'function' && define.amd)\n\t\tdefine([], factory);\n\telse if(typeof exports === 'object')\n\t\texports[\"polykey\"] = factory();\n\telse\n\t\troot[\"polykey\"] = factory();\n})(this, function() {\nreturn "," \t// The module cache\n \tvar installedModules = {};\n\n \t// The require function\n \tfunction __webpack_require__(moduleId) {\n\n \t\t// Check if module is in cache\n \t\tif(installedModules[moduleId]) {\n \t\t\treturn installedModules[moduleId].exports;\n \t\t}\n \t\t// Create a new module (and put it into the cache)\n \t\tvar module = installedModules[moduleId] = {\n \t\t\ti: moduleId,\n \t\t\tl: false,\n \t\t\texports: {}\n \t\t};\n\n \t\t// Execute the module function\n \t\tmodules[moduleId].call(module.exports, module, module.exports, __webpack_require__);\n\n \t\t// Flag the module as loaded\n \t\tmodule.l = true;\n\n \t\t// Return the exports of the module\n \t\treturn module.exports;\n \t}\n\n\n \t// expose the modules object (__webpack_modules__)\n \t__webpack_require__.m = modules;\n\n \t// expose the module cache\n \t__webpack_require__.c = installedModules;\n\n \t// define getter function for harmony exports\n \t__webpack_require__.d = function(exports, name, getter) {\n \t\tif(!__webpack_require__.o(exports, name)) {\n \t\t\tObject.defineProperty(exports, name, { enumerable: true, get: getter });\n \t\t}\n \t};\n\n \t// define __esModule on exports\n \t__webpack_require__.r = function(exports) {\n \t\tif(typeof Symbol !== 'undefined' && Symbol.toStringTag) {\n \t\t\tObject.defineProperty(exports, Symbol.toStringTag, { value: 'Module' });\n \t\t}\n \t\tObject.defineProperty(exports, '__esModule', { value: true });\n \t};\n\n \t// create a fake namespace object\n \t// mode & 1: value is a module id, require it\n \t// mode & 2: merge all properties of value into the ns\n \t// mode & 4: return value when already ns object\n \t// mode & 8|1: behave like require\n \t__webpack_require__.t = function(value, mode) {\n \t\tif(mode & 1) value = __webpack_require__(value);\n \t\tif(mode & 8) return value;\n \t\tif((mode & 4) && typeof value === 'object' && value && value.__esModule) return value;\n \t\tvar ns = Object.create(null);\n \t\t__webpack_require__.r(ns);\n \t\tObject.defineProperty(ns, 'default', { enumerable: true, value: value });\n \t\tif(mode & 2 && typeof value != 'string') for(var key in value) __webpack_require__.d(ns, key, function(key) { return value[key]; }.bind(null, key));\n \t\treturn ns;\n \t};\n\n \t// getDefaultExport function for compatibility with non-harmony modules\n \t__webpack_require__.n = function(module) {\n \t\tvar getter = module && module.__esModule ?\n \t\t\tfunction getDefault() { return module['default']; } :\n \t\t\tfunction getModuleExports() { return module; };\n \t\t__webpack_require__.d(getter, 'a', getter);\n \t\treturn getter;\n \t};\n\n \t// Object.prototype.hasOwnProperty.call\n \t__webpack_require__.o = function(object, property) { return Object.prototype.hasOwnProperty.call(object, property); };\n\n \t// __webpack_public_path__\n \t__webpack_require__.p = \"\";\n\n\n \t// Load entry module and return exports\n \treturn __webpack_require__(__webpack_require__.s = 4);\n","module.exports = require(\"path\");","module.exports = require(\"os\");","module.exports = require(\"fs\");","module.exports = require(\"readable-stream\");","\"use strict\";\nvar __importDefault = (this && this.__importDefault) || function (mod) {\n    return (mod && mod.__esModule) ? mod : { \"default\": mod };\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nconst os_1 = __importDefault(require(\"os\"));\nconst KeyManager_1 = __importDefault(require(\"./keys/KeyManager\"));\nexports.KeyManager = KeyManager_1.default;\nconst PeerManager_1 = __importDefault(require(\"./peers/PeerManager\"));\nexports.PeerManager = PeerManager_1.default;\nconst VaultManager_1 = __importDefault(require(\"./vaults/VaultManager\"));\nexports.VaultManager = VaultManager_1.default;\nconst PolykeyAgent_1 = __importDefault(require(\"./agent/PolykeyAgent\"));\nexports.PolykeyAgent = PolykeyAgent_1.default;\nconst PolykeyClient_1 = __importDefault(require(\"./agent/PolykeyClient\"));\nexports.PolykeyClient = PolykeyClient_1.default;\nclass Polykey {\n    constructor(polykeyPath = `${os_1.default.homedir()}/.polykey`, fileSystem, keyManager, vaultManager, peerManager) {\n        this.polykeyPath = polykeyPath;\n        // Set key manager\n        this.keyManager = keyManager !== null && keyManager !== void 0 ? keyManager : new KeyManager_1.default(this.polykeyPath, fileSystem);\n        // Set or Initialize vaultManager\n        this.vaultManager = vaultManager !== null && vaultManager !== void 0 ? vaultManager : new VaultManager_1.default(this.polykeyPath, fileSystem, this.keyManager);\n        // Initialize peer store and peer discovery classes\n        this.peerManager = peerManager !== null && peerManager !== void 0 ? peerManager : new PeerManager_1.default(this.polykeyPath, fileSystem, this.keyManager, this.vaultManager);\n    }\n}\nexports.default = Polykey;\n","module.exports = require(\"crypto\");","module.exports = require(\"@grpc/grpc-js\");","module.exports = require(\"../../proto/compiled/Git_grpc_pb\");","module.exports = require(\"../../proto/compiled/Git_pb\");","\"use strict\";\n/**\npkt-line Format\n---------------\n\nMuch (but not all) of the payload is described around pkt-lines.\n\nA pkt-line is a variable length binary string.  The first four bytes\nof the line, the pkt-len, indicates the total length of the line,\nin hexadecimal.  The pkt-len includes the 4 bytes used to contain\nthe length's hexadecimal representation.\n\nA pkt-line MAY contain binary data, so implementors MUST ensure\npkt-line parsing/formatting routines are 8-bit clean.\n\nA non-binary line SHOULD BE terminated by an LF, which if present\nMUST be included in the total length. Receivers MUST treat pkt-lines\nwith non-binary data the same whether or not they contain the trailing\nLF (stripping the LF if present, and not complaining when it is\nmissing).\n\nThe maximum length of a pkt-line's data component is 65516 bytes.\nImplementations MUST NOT send pkt-line whose length exceeds 65520\n(65516 bytes of payload + 4 bytes of length data).\n\nImplementations SHOULD NOT send an empty pkt-line (\"0004\").\n\nA pkt-line with a length field of 0 (\"0000\"), called a flush-pkt,\nis a special case and MUST be handled differently than an empty\npkt-line (\"0004\").\n\n----\n  pkt-line     =  data-pkt / flush-pkt\n\n  data-pkt     =  pkt-len pkt-payload\n  pkt-len      =  4*(HEXDIG)\n  pkt-payload  =  (pkt-len - 4)*(OCTET)\n\n  flush-pkt    = \"0000\"\n----\n\nExamples (as C-style strings):\n\n----\n  pkt-line          actual value\n  ---------------------------------\n  \"0006a\\n\"         \"a\\n\"\n  \"0005a\"           \"a\"\n  \"000bfoobar\\n\"    \"foobar\\n\"\n  \"0004\"            \"\"\n----\n*/\nObject.defineProperty(exports, \"__esModule\", { value: true });\nfunction padHex(b, n) {\n    const s = n.toString(16);\n    return '0'.repeat(b - s.length) + s;\n}\n// I'm really using this more as a namespace.\n// There's not a lot of \"state\" in a pkt-line\nclass GitPktLine {\n    static flush() {\n        return Buffer.from('0000', 'utf8');\n    }\n    static encode(line) {\n        if (typeof line === 'string') {\n            line = Buffer.from(line);\n        }\n        const length = line.length + 4;\n        const hexlength = padHex(4, length);\n        return Buffer.concat([Buffer.from(hexlength, 'utf8'), line]);\n    }\n    static streamReader(stream) {\n        return async function read() {\n            try {\n                let length = await stream.slice(4);\n                if (length === null)\n                    return true;\n                length = parseInt(length.toString('utf8'), 16);\n                if (length === 0)\n                    return null;\n                let buffer = await stream.slice(length - 4);\n                if (buffer === null)\n                    return true;\n                return buffer;\n            }\n            catch (err) {\n                console.log('error', err);\n                return true;\n            }\n        };\n    }\n}\nexports.default = GitPktLine;\n","\"use strict\";\nvar __importDefault = (this && this.__importDefault) || function (mod) {\n    return (mod && mod.__esModule) ? mod : { \"default\": mod };\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\n// This is a convenience wrapper for reading and writing files in the 'refs' directory.\nconst path_1 = __importDefault(require(\"path\"));\nconst GitPackedRefs_1 = __importDefault(require(\"./GitPackedRefs\"));\n// @see https://git-scm.com/docs/git-rev-parse.html#_specifying_revisions\nconst refpaths = (ref) => [\n    `${ref}`,\n    `refs/${ref}`,\n    `refs/tags/${ref}`,\n    `refs/heads/${ref}`,\n    `refs/remotes/${ref}`,\n    `refs/remotes/${ref}/HEAD`,\n];\nfunction compareRefNames(a, b) {\n    // https://stackoverflow.com/a/40355107/2168416\n    const _a = a.replace(/\\^\\{\\}$/, '');\n    const _b = b.replace(/\\^\\{\\}$/, '');\n    const tmp = -(_a < _b) || +(_a > _b);\n    if (tmp === 0) {\n        return a.endsWith('^{}') ? 1 : -1;\n    }\n    return tmp;\n}\n// @see https://git-scm.com/docs/gitrepository-layout\nconst GIT_FILES = ['config', 'description', 'index', 'shallow', 'commondir'];\n// This function is used to get all the files in the refs folder for listRefs function\nasync function recursiveDirectoryWalk(dir, fileSystem) {\n    return new Promise((resolve, reject) => {\n        let results = [];\n        fileSystem.promises\n            .readdir(dir)\n            .then(async (list) => {\n            var pending = list.length;\n            if (!pending)\n                return resolve(results);\n            list.forEach(async function (file) {\n                file = path_1.default.resolve(dir, file);\n                fileSystem.promises.stat(file).then(async (stat) => {\n                    if (stat && stat.isDirectory()) {\n                        const res = await recursiveDirectoryWalk(file, fileSystem);\n                        results = results.concat(res);\n                        if (!--pending)\n                            resolve(results);\n                    }\n                    else {\n                        results.push(file);\n                        if (!--pending)\n                            resolve(results);\n                    }\n                });\n            });\n        })\n            .catch((err) => {\n            if (err)\n                return reject(err);\n        });\n    });\n}\nclass GitRefManager {\n    static async packedRefs(fileSystem, gitdir) {\n        const text = fileSystem.readFileSync(`${gitdir}/packed-refs`, { encoding: 'utf8' });\n        const packed = GitPackedRefs_1.default.from(text);\n        return packed.refs;\n    }\n    // List all the refs that match the `filepath` prefix\n    static async listRefs(fileSystem, gitdir, filepath) {\n        const packedMap = GitRefManager.packedRefs(fileSystem, gitdir);\n        let files = [];\n        try {\n            files = await recursiveDirectoryWalk(`${gitdir}/${filepath}`, fileSystem);\n            files = files.map((x) => x.replace(`${gitdir}/${filepath}/`, ''));\n        }\n        catch (err) {\n            files = [];\n        }\n        for (let key of (await packedMap).keys()) {\n            // filter by prefix\n            if (key.startsWith(filepath)) {\n                // remove prefix\n                key = key.replace(filepath + '/', '');\n                // Don't include duplicates; the loose files have precedence anyway\n                if (!files.includes(key)) {\n                    files.push(key);\n                }\n            }\n        }\n        // since we just appended things onto an array, we need to sort them now\n        files.sort(compareRefNames);\n        return files;\n    }\n    static async resolve(fileSystem, gitdir, ref, depth) {\n        if (depth !== undefined) {\n            depth--;\n            if (depth === -1) {\n                return ref;\n            }\n        }\n        // Is it a ref pointer?\n        if (ref.startsWith('ref: ')) {\n            ref = ref.slice('ref: '.length);\n            return GitRefManager.resolve(fileSystem, gitdir, ref, depth);\n        }\n        // Is it a complete and valid SHA?\n        if (ref.length === 40 && /[0-9a-f]{40}/.test(ref)) {\n            return ref;\n        }\n        // We need to alternate between the file system and the packed-refs\n        const packedMap = await GitRefManager.packedRefs(fileSystem, gitdir);\n        // Look in all the proper paths, in this order\n        const allpaths = refpaths(ref).filter((p) => !GIT_FILES.includes(p)); // exclude git system files (#709)\n        for (const ref of allpaths) {\n            const sha = fileSystem.readFileSync(`${gitdir}/${ref}`, { encoding: 'utf8' }).toString() || packedMap.get(ref);\n            if (sha) {\n                return GitRefManager.resolve(fileSystem, gitdir, sha.trim(), depth);\n            }\n        }\n        // Do we give up?\n        throw Error('RefNotFound');\n    }\n}\nexports.default = GitRefManager;\n","module.exports = require(\"pako\");","\"use strict\";\n// The amount of work that went into crafting these cases to handle\n// -0 (just so we don't lose that information when parsing and reconstructing)\n// but can also default to +0 was extraordinary.\nObject.defineProperty(exports, \"__esModule\", { value: true });\nfunction simpleSign(n) {\n    return Math.sign(n) || (Object.is(n, -0) ? -1 : 1);\n}\nfunction negateExceptForZero(n) {\n    return n === 0 ? n : -n;\n}\nfunction formatTimezoneOffset(minutes) {\n    let sign = simpleSign(negateExceptForZero(minutes));\n    minutes = Math.abs(minutes);\n    let hours = Math.floor(minutes / 60);\n    minutes -= hours * 60;\n    let strHours = String(hours);\n    let strMinutes = String(minutes);\n    if (strHours.length < 2)\n        strHours = '0' + strHours;\n    if (strMinutes.length < 2)\n        strMinutes = '0' + strMinutes;\n    return (sign === -1 ? '-' : '+') + strHours + strMinutes;\n}\nfunction parseTimezoneOffset(offset) {\n    let [, sign, hours, minutes] = offset.match(/(\\+|-)(\\d\\d)(\\d\\d)/);\n    minutes = (sign === '+' ? 1 : -1) * (Number(hours) * 60 + Number(minutes));\n    return negateExceptForZero(minutes);\n}\nfunction parseAuthor(author) {\n    let [, name, email, timestamp, offset] = author.match(/^(.*) <(.*)> (.*) (.*)$/);\n    return {\n        name: name,\n        email: email,\n        timestamp: Number(timestamp),\n        timezoneOffset: parseTimezoneOffset(offset),\n    };\n}\nfunction normalize(str) {\n    // remove all <CR>\n    str = str.replace(/\\r/g, '');\n    // no extra newlines up front\n    str = str.replace(/^\\n+/, '');\n    // and a single newline at the end\n    str = str.replace(/\\n+$/, '') + '\\n';\n    return str;\n}\nfunction indent(str) {\n    return (str\n        .trim()\n        .split('\\n')\n        .map((x) => ' ' + x)\n        .join('\\n') + '\\n');\n}\nfunction outdent(str) {\n    return str\n        .split('\\n')\n        .map((x) => x.replace(/^ /, ''))\n        .join('\\n');\n}\n// TODO: Make all functions have static async signature?\nclass GitCommit {\n    constructor(commit) {\n        if (typeof commit === 'string') {\n            this._commit = commit;\n        }\n        else if (Buffer.isBuffer(commit)) {\n            this._commit = commit.toString('utf8');\n        }\n        else if (typeof commit === 'object') {\n            this._commit = GitCommit.render(commit);\n        }\n        else {\n            throw new Error('invalid type passed to GitCommit constructor');\n        }\n    }\n    static fromPayloadSignature({ payload, signature }) {\n        let headers = GitCommit.justHeaders(payload);\n        let message = GitCommit.justMessage(payload);\n        let commit = normalize(headers + '\\ngpgsig' + indent(signature) + '\\n' + message);\n        return new GitCommit(commit);\n    }\n    static from(commit) {\n        return new GitCommit(commit);\n    }\n    toObject() {\n        return Buffer.from(this._commit, 'utf8');\n    }\n    // Todo: allow setting the headers and message\n    headers() {\n        return this.parseHeaders();\n    }\n    // Todo: allow setting the headers and message\n    message() {\n        return GitCommit.justMessage(this._commit);\n    }\n    parse() {\n        return Object.assign({ message: this.message() }, this.headers());\n    }\n    static justMessage(commit) {\n        return normalize(commit.slice(commit.indexOf('\\n\\n') + 2));\n    }\n    static justHeaders(commit) {\n        return commit.slice(0, commit.indexOf('\\n\\n'));\n    }\n    parseHeaders() {\n        let headers = GitCommit.justHeaders(this._commit).split('\\n');\n        let hs = [];\n        for (let h of headers) {\n            if (h[0] === ' ') {\n                // combine with previous header (without space indent)\n                hs[hs.length - 1] += '\\n' + h.slice(1);\n            }\n            else {\n                hs.push(h);\n            }\n        }\n        let obj = {\n            parent: [],\n        };\n        for (let h of hs) {\n            let key = h.slice(0, h.indexOf(' '));\n            let value = h.slice(h.indexOf(' ') + 1);\n            if (Array.isArray(obj[key])) {\n                obj[key].push(value);\n            }\n            else {\n                obj[key] = value;\n            }\n        }\n        if (obj.author) {\n            obj.author = parseAuthor(obj.author);\n        }\n        if (obj.committer) {\n            obj.committer = parseAuthor(obj.committer);\n        }\n        return obj;\n    }\n    static renderHeaders(obj) {\n        let headers = '';\n        if (obj.tree) {\n            headers += `tree ${obj.tree}\\n`;\n        }\n        else {\n            headers += `tree 4b825dc642cb6eb9a060e54bf8d69288fbee4904\\n`; // the null tree\n        }\n        if (obj.parent) {\n            if (obj.parent.length === undefined) {\n                throw new Error(`commit 'parent' property should be an array`);\n            }\n            for (let p of obj.parent) {\n                headers += `parent ${p}\\n`;\n            }\n        }\n        let author = obj.author;\n        headers += `author ${author.name} <${author.email}> ${author.timestamp} ${formatTimezoneOffset(author.timezoneOffset)}\\n`;\n        let committer = obj.committer || obj.author;\n        headers += `committer ${committer.name} <${committer.email}> ${committer.timestamp} ${formatTimezoneOffset(committer.timezoneOffset)}\\n`;\n        if (obj.gpgsig) {\n            headers += 'gpgsig' + indent(obj.gpgsig);\n        }\n        return headers;\n    }\n    static render(obj) {\n        return GitCommit.renderHeaders(obj) + '\\n' + normalize(obj.message);\n    }\n    render() {\n        return this._commit;\n    }\n    withoutSignature() {\n        let commit = normalize(this._commit);\n        if (commit.indexOf('\\ngpgsig') === -1)\n            return commit;\n        let headers = commit.slice(0, commit.indexOf('\\ngpgsig'));\n        let message = commit.slice(commit.indexOf('-----END PGP SIGNATURE-----\\n') + '-----END PGP SIGNATURE-----\\n'.length);\n        return normalize(headers + '\\n' + message);\n    }\n    isolateSignature() {\n        let signature = this._commit.slice(this._commit.indexOf('-----BEGIN PGP SIGNATURE-----'), this._commit.indexOf('-----END PGP SIGNATURE-----') + '-----END PGP SIGNATURE-----'.length);\n        return outdent(signature);\n    }\n}\nexports.default = GitCommit;\n","\"use strict\";\nvar __importDefault = (this && this.__importDefault) || function (mod) {\n    return (mod && mod.__esModule) ? mod : { \"default\": mod };\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nconst fs_1 = __importDefault(require(\"fs\"));\nconst pako_1 = __importDefault(require(\"pako\"));\nconst path_1 = __importDefault(require(\"path\"));\nconst GitObject_1 = __importDefault(require(\"./GitObject\"));\nconst PackfileCache = new Map();\nclass GitObjectManager {\n    static async read(fileSystem, gitdir, oid, format = 'content') {\n        // Look for it in the loose object directory.\n        let file = fileSystem.readFileSync(`${gitdir}/objects/${oid.slice(0, 2)}/${oid.slice(2)}`);\n        let source = `./objects/${oid.slice(0, 2)}/${oid.slice(2)}`;\n        // Check to see if it's in a packfile.\n        if (!file) {\n            // Curry the current read method so that the packfile un-deltification\n            // process can acquire external ref-deltas.\n            const getExternalRefDelta = (oid) => GitObjectManager.read(fileSystem, gitdir, oid);\n            // Iterate through all the .pack files\n            let list = fs_1.default.readdirSync(path_1.default.join(gitdir, '/objects/pack'));\n            list = list.filter((x) => x.endsWith('.pack'));\n            for (let filename of list) {\n                // Try to get the packfile from the in-memory cache\n                let p = PackfileCache.get(filename);\n                // If the packfile DOES have the oid we're looking for...\n                if (p.offsets.has(oid)) {\n                    // Make sure the packfile is loaded in memory\n                    if (!p.pack) {\n                        const pack = fileSystem.readFileSync(`${gitdir}/objects/pack/${filename}`);\n                        await p.load({ pack });\n                    }\n                    // Get the resolved git object from the packfile\n                    let result = await p.read({ oid, getExternalRefDelta });\n                    result.source = `./objects/pack/${filename}`;\n                    return result;\n                }\n            }\n        }\n        // Check to see if it's in shallow commits.\n        if (!file) {\n            let text = fileSystem.readFileSync(`${gitdir}/shallow`, { encoding: 'utf8' });\n            if (text !== null && text.includes(oid)) {\n                throw new Error(`ReadShallowObjectFail: ${oid}`);\n            }\n        }\n        // Finally\n        if (!file) {\n            throw new Error(`ReadObjectFail: ${oid}`);\n        }\n        if (format === 'deflated') {\n            return { format: 'deflated', object: file, source };\n        }\n        let buffer = Buffer.from(pako_1.default.inflate(file));\n        if (format === 'wrapped') {\n            return { format: 'wrapped', object: buffer, source };\n        }\n        let { type, object } = GitObject_1.default.unwrap({ oid, buffer });\n        if (format === 'content')\n            return { type, format: 'content', object, source };\n    }\n}\nexports.default = GitObjectManager;\n","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nclass Address {\n    constructor(ip, port) {\n        this.ip = ip;\n        this.port = port;\n    }\n    /**\n     * Create an address object from a address string\n     * @param addressString Address string in the format of `${this.ip}:${this.port}`\n     */\n    static parse(addressString) {\n        const components = addressString.split(':');\n        const ip = components[0];\n        const port = components[1];\n        return new Address(ip, port);\n    }\n    /**\n     * Create an address object from a net.AddressInfo\n     * @param addressInfo AddressInfo of desired address\n     */\n    static fromAddressInfo(addressInfo) {\n        const ip = addressInfo.address == '::' ? 'localhost' : addressInfo.address;\n        return new Address(ip, addressInfo.port.toString());\n    }\n    /**\n     * Convert address into string of format `${this.ip}:${this.port}`\n     */\n    toString() {\n        return `${this.ip}:${this.port}`;\n    }\n}\nexports.Address = Address;\nAddress.prototype.toString = function () {\n    return `${this.ip}:${this.port}`;\n};\nclass PeerInfo {\n    constructor(pubKey, addresses = [], connectedAddr) {\n        this.publicKey = pubKey;\n        this.addresses = new Set(addresses.map((addr) => {\n            return Address.parse(addr);\n        }));\n        this.connectedAddr = connectedAddr ? Address.parse(connectedAddr) : undefined;\n    }\n    /**\n     * Sets the main server address for the peer\n     * @param address Main server address for peer\n     */\n    connect(address) {\n        if (!this.addresses.has(address)) {\n            this.addresses.add(address);\n        }\n        this.connectedAddr = address;\n    }\n    /**\n     * Clears the main server address for the peer\n     */\n    disconnect() {\n        this.connectedAddr = undefined;\n    }\n    get AdressStringList() {\n        return Array.from(this.addresses.values()).map((addr) => {\n            return addr.toString();\n        });\n    }\n}\nexports.default = PeerInfo;\n","module.exports = require(\"isomorphic-git\");","module.exports = require(\"encryptedfs\");","module.exports = require(\"virtualfs\");","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nconst Agent_1 = require(\"../../../proto/js/Agent\");\nconst { AgentMessage, AgentMessageType, CreateSecretRequestMessage, CreateSecretResponseMessage, DecryptFileRequestMessage, DecryptFileResponseMessage, DeleteKeyRequestMessage, DeleteKeyResponseMessage, DeriveKeyRequestMessage, DeriveKeyResponseMessage, DestroySecretRequestMessage, DestroySecretResponseMessage, DestroyVaultRequestMessage, DestroyVaultResponseMessage, EncryptFileRequestMessage, EncryptFileResponseMessage, ErrorMessage, GetPrimaryKeyPairRequestMessage, GetPrimaryKeyPairResponseMessage, GetSecretRequestMessage, GetSecretResponseMessage, GetKeyRequestMessage, GetKeyResponseMessage, ListKeysRequestMessage, ListKeysResponseMessage, ListNodesRequestMessage, ListNodesResponseMessage, ListSecretsRequestMessage, ListSecretsResponseMessage, ListVaultsRequestMessage, ListVaultsResponseMessage, NewNodeRequestMessage, NewNodeResponseMessage, NewVaultRequestMessage, NewVaultResponseMessage, RegisterNodeRequestMessage, RegisterNodeResponseMessage, SignFileRequestMessage, SignFileResponseMessage, UpdateSecretRequestMessage, UpdateSecretResponseMessage, VerifyFileRequestMessage, VerifyFileResponseMessage, } = Agent_1.agent;\nclass PolykeyClient {\n    constructor(getStream) {\n        this.getStream = getStream;\n    }\n    async sendRequestToAgent(request) {\n        const stream = this.getStream();\n        const responseList = await new Promise((resolve, reject) => {\n            try {\n                const responseList = [];\n                stream.on('data', (data) => {\n                    if (data instanceof Uint8Array) {\n                        responseList.push(data);\n                    }\n                    else {\n                        responseList.push(...data);\n                    }\n                });\n                stream.on('error', (err) => {\n                    reject(err);\n                });\n                stream.on('end', () => {\n                    resolve(responseList);\n                });\n                if (!stream.writableEnded) {\n                    stream.write(request);\n                }\n            }\n            catch (err) {\n                reject(err);\n            }\n        });\n        return responseList;\n    }\n    async handleAgentCommunication(type, nodePath, request) {\n        // Encode message and sent\n        const agentMessage = AgentMessage.encode({\n            type: type,\n            isResponse: false,\n            nodePath: nodePath,\n            subMessage: request,\n        }).finish();\n        const responseList = await this.sendRequestToAgent(agentMessage);\n        const agentMessageList = [];\n        for (const response of responseList.values()) {\n            const { subMessage, type } = AgentMessage.decode(response);\n            if (type == AgentMessageType.ERROR) {\n                const { error } = ErrorMessage.decode(subMessage);\n                const reason = new Error(`Agent Error: ${error}`);\n                throw reason;\n            }\n            else {\n                agentMessageList.push(AgentMessage.decode(response));\n            }\n        }\n        return agentMessageList;\n    }\n    async registerNode(path, passphrase) {\n        var _a;\n        const registerNodeRequest = RegisterNodeRequestMessage.encode({ passphrase }).finish();\n        const encodedResponse = await this.handleAgentCommunication(AgentMessageType.REGISTER_NODE, path, registerNodeRequest);\n        const subMessage = (_a = encodedResponse.find((r) => r.type == AgentMessageType.REGISTER_NODE)) === null || _a === void 0 ? void 0 : _a.subMessage;\n        if (!subMessage) {\n            throw Error('agent did not respond');\n        }\n        const { successful } = RegisterNodeResponseMessage.decode(subMessage);\n        return successful;\n    }\n    async newNode(path, name, email, passphrase, nbits) {\n        var _a;\n        const newNodeRequest = NewNodeRequestMessage.encode({ name, email, passphrase, nbits }).finish();\n        const encodedResponse = await this.handleAgentCommunication(AgentMessageType.NEW_NODE, path, newNodeRequest);\n        const subMessage = (_a = encodedResponse.find((r) => r.type == AgentMessageType.NEW_NODE)) === null || _a === void 0 ? void 0 : _a.subMessage;\n        if (!subMessage) {\n            throw Error('agent did not respond');\n        }\n        const { successful } = NewNodeResponseMessage.decode(subMessage);\n        return successful;\n    }\n    async listNodes(unlockedOnly = true) {\n        var _a;\n        const newNodeRequest = ListNodesRequestMessage.encode({ unlockedOnly }).finish();\n        const encodedResponse = await this.handleAgentCommunication(AgentMessageType.LIST_NODES, undefined, newNodeRequest);\n        const subMessage = (_a = encodedResponse.find((r) => r.type == AgentMessageType.LIST_NODES)) === null || _a === void 0 ? void 0 : _a.subMessage;\n        if (!subMessage) {\n            throw Error('agent did not respond');\n        }\n        const { nodes } = ListNodesResponseMessage.decode(subMessage);\n        return nodes;\n    }\n    /////////////////////\n    // Key commands //\n    /////////////////////\n    async deriveKey(nodePath, keyName, passphrase) {\n        var _a;\n        const request = DeriveKeyRequestMessage.encode({ keyName, passphrase }).finish();\n        const encodedResponse = await this.handleAgentCommunication(AgentMessageType.DERIVE_KEY, nodePath, request);\n        const subMessage = (_a = encodedResponse.find((r) => r.type == AgentMessageType.DERIVE_KEY)) === null || _a === void 0 ? void 0 : _a.subMessage;\n        if (!subMessage) {\n            throw Error('agent did not respond');\n        }\n        const { successful } = DeriveKeyResponseMessage.decode(subMessage);\n        return successful;\n    }\n    async deleteKey(nodePath, keyName) {\n        var _a;\n        const request = DeleteKeyRequestMessage.encode({ keyName }).finish();\n        const encodedResponse = await this.handleAgentCommunication(AgentMessageType.DELETE_KEY, nodePath, request);\n        const subMessage = (_a = encodedResponse.find((r) => r.type == AgentMessageType.DELETE_KEY)) === null || _a === void 0 ? void 0 : _a.subMessage;\n        if (!subMessage) {\n            throw Error('agent did not respond');\n        }\n        const { successful } = DeleteKeyResponseMessage.decode(subMessage);\n        return successful;\n    }\n    async listKeys(nodePath) {\n        var _a;\n        const request = ListKeysRequestMessage.encode({}).finish();\n        const encodedResponse = await this.handleAgentCommunication(AgentMessageType.LIST_KEYS, nodePath, request);\n        const subMessage = (_a = encodedResponse.find((r) => r.type == AgentMessageType.LIST_KEYS)) === null || _a === void 0 ? void 0 : _a.subMessage;\n        if (!subMessage) {\n            throw Error('agent did not respond');\n        }\n        const { keyNames } = ListKeysResponseMessage.decode(subMessage);\n        return keyNames;\n    }\n    async getKey(nodePath, keyName) {\n        var _a;\n        const request = GetKeyRequestMessage.encode({ keyName }).finish();\n        const encodedResponse = await this.handleAgentCommunication(AgentMessageType.GET_KEY, nodePath, request);\n        const subMessage = (_a = encodedResponse.find((r) => r.type == AgentMessageType.GET_KEY)) === null || _a === void 0 ? void 0 : _a.subMessage;\n        if (!subMessage) {\n            throw Error('agent did not respond');\n        }\n        const { keyContent } = GetKeyResponseMessage.decode(subMessage);\n        return keyContent;\n    }\n    async getPrimaryKeyPair(nodePath, includePrivateKey = false) {\n        var _a;\n        const request = GetPrimaryKeyPairRequestMessage.encode({ includePrivateKey }).finish();\n        const encodedResponse = await this.handleAgentCommunication(AgentMessageType.GET_PRIMARY_KEYPAIR, nodePath, request);\n        const subMessage = (_a = encodedResponse.find((r) => r.type == AgentMessageType.GET_PRIMARY_KEYPAIR)) === null || _a === void 0 ? void 0 : _a.subMessage;\n        if (!subMessage) {\n            throw Error('agent did not respond');\n        }\n        const { publicKey, privateKey } = GetPrimaryKeyPairResponseMessage.decode(subMessage);\n        return { publicKey, privateKey };\n    }\n    /////////////////////\n    // Crypto commands //\n    /////////////////////\n    async signFile(nodePath, filePath, privateKeyPath, passphrase) {\n        var _a;\n        const request = SignFileRequestMessage.encode({ filePath, privateKeyPath, passphrase }).finish();\n        const encodedResponse = await this.handleAgentCommunication(AgentMessageType.SIGN_FILE, nodePath, request);\n        const subMessage = (_a = encodedResponse.find((r) => r.type == AgentMessageType.SIGN_FILE)) === null || _a === void 0 ? void 0 : _a.subMessage;\n        if (!subMessage) {\n            throw Error('agent did not respond');\n        }\n        const { signaturePath } = SignFileResponseMessage.decode(subMessage);\n        return signaturePath;\n    }\n    async verifyFile(nodePath, filePath, publicKeyPath) {\n        var _a;\n        const request = VerifyFileRequestMessage.encode({ filePath, publicKeyPath }).finish();\n        const encodedResponse = await this.handleAgentCommunication(AgentMessageType.VERIFY_FILE, nodePath, request);\n        const subMessage = (_a = encodedResponse.find((r) => r.type == AgentMessageType.VERIFY_FILE)) === null || _a === void 0 ? void 0 : _a.subMessage;\n        if (!subMessage) {\n            throw Error('agent did not respond');\n        }\n        const { verified } = VerifyFileResponseMessage.decode(subMessage);\n        return verified;\n    }\n    async encryptFile(nodePath, filePath, publicKeyPath) {\n        var _a;\n        const request = EncryptFileRequestMessage.encode({ filePath, publicKeyPath }).finish();\n        const encodedResponse = await this.handleAgentCommunication(AgentMessageType.ENCRYPT_FILE, nodePath, request);\n        const subMessage = (_a = encodedResponse.find((r) => r.type == AgentMessageType.ENCRYPT_FILE)) === null || _a === void 0 ? void 0 : _a.subMessage;\n        if (!subMessage) {\n            throw Error('agent did not respond');\n        }\n        const { encryptedPath } = EncryptFileResponseMessage.decode(subMessage);\n        return encryptedPath;\n    }\n    async decryptFile(nodePath, filePath, privateKeyPath, passphrase) {\n        var _a;\n        const request = DecryptFileRequestMessage.encode({ filePath, privateKeyPath, passphrase }).finish();\n        const encodedResponse = await this.handleAgentCommunication(AgentMessageType.DECRYPT_FILE, nodePath, request);\n        const subMessage = (_a = encodedResponse.find((r) => r.type == AgentMessageType.DECRYPT_FILE)) === null || _a === void 0 ? void 0 : _a.subMessage;\n        if (!subMessage) {\n            throw Error('agent did not respond');\n        }\n        const { decryptedPath } = DecryptFileResponseMessage.decode(subMessage);\n        return decryptedPath;\n    }\n    //////////////////////\n    // Vault Operations //\n    //////////////////////\n    async listVaults(nodePath) {\n        var _a;\n        const encodedResponse = await this.handleAgentCommunication(AgentMessageType.LIST_VAULTS, nodePath);\n        const subMessage = (_a = encodedResponse.find((r) => r.type == AgentMessageType.LIST_VAULTS)) === null || _a === void 0 ? void 0 : _a.subMessage;\n        if (!subMessage) {\n            throw Error('agent did not respond');\n        }\n        const { vaultNames } = ListVaultsResponseMessage.decode(subMessage);\n        return vaultNames;\n    }\n    async newVault(nodePath, vaultName) {\n        var _a;\n        const request = NewVaultRequestMessage.encode({ vaultName }).finish();\n        const encodedResponse = await this.handleAgentCommunication(AgentMessageType.NEW_VAULT, nodePath, request);\n        const subMessage = (_a = encodedResponse.find((r) => r.type == AgentMessageType.NEW_VAULT)) === null || _a === void 0 ? void 0 : _a.subMessage;\n        if (!subMessage) {\n            throw Error('agent did not respond');\n        }\n        const { successful } = NewVaultResponseMessage.decode(subMessage);\n        return successful;\n    }\n    async destroyVault(nodePath, vaultName) {\n        var _a;\n        const request = DestroyVaultRequestMessage.encode({ vaultName }).finish();\n        const encodedResponse = await this.handleAgentCommunication(AgentMessageType.DESTROY_VAULT, nodePath, request);\n        const subMessage = (_a = encodedResponse.find((r) => r.type == AgentMessageType.DESTROY_VAULT)) === null || _a === void 0 ? void 0 : _a.subMessage;\n        if (!subMessage) {\n            throw Error('agent did not respond');\n        }\n        const { successful } = DestroyVaultResponseMessage.decode(subMessage);\n        return successful;\n    }\n    ///////////////////////\n    // Secret Operations //\n    ///////////////////////\n    async listSecrets(nodePath, vaultName) {\n        var _a;\n        const request = ListSecretsRequestMessage.encode({ vaultName }).finish();\n        const encodedResponse = await this.handleAgentCommunication(AgentMessageType.LIST_SECRETS, nodePath, request);\n        const subMessage = (_a = encodedResponse.find((r) => r.type == AgentMessageType.LIST_SECRETS)) === null || _a === void 0 ? void 0 : _a.subMessage;\n        if (!subMessage) {\n            throw Error('agent did not respond');\n        }\n        const { secretNames } = ListSecretsResponseMessage.decode(subMessage);\n        return secretNames;\n    }\n    async createSecret(nodePath, vaultName, secretName, secret) {\n        var _a;\n        let request;\n        if (typeof secret == 'string') {\n            request = CreateSecretRequestMessage.encode({ vaultName, secretName, secretPath: secret }).finish();\n        }\n        else {\n            request = CreateSecretRequestMessage.encode({ vaultName, secretName, secretContent: secret }).finish();\n        }\n        const encodedResponse = await this.handleAgentCommunication(AgentMessageType.CREATE_SECRET, nodePath, request);\n        const subMessage = (_a = encodedResponse.find((r) => r.type == AgentMessageType.CREATE_SECRET)) === null || _a === void 0 ? void 0 : _a.subMessage;\n        if (!subMessage) {\n            throw Error('agent did not respond');\n        }\n        const { successful } = CreateSecretResponseMessage.decode(subMessage);\n        return successful;\n    }\n    async destroySecret(nodePath, vaultName, secretName) {\n        var _a;\n        const request = DestroySecretRequestMessage.encode({ vaultName, secretName }).finish();\n        const encodedResponse = await this.handleAgentCommunication(AgentMessageType.DESTROY_SECRET, nodePath, request);\n        const subMessage = (_a = encodedResponse.find((r) => r.type == AgentMessageType.DESTROY_SECRET)) === null || _a === void 0 ? void 0 : _a.subMessage;\n        if (!subMessage) {\n            throw Error('agent did not respond');\n        }\n        const { successful } = DestroySecretResponseMessage.decode(subMessage);\n        return successful;\n    }\n    async getSecret(nodePath, vaultName, secretName) {\n        var _a;\n        const request = GetSecretRequestMessage.encode({ vaultName, secretName }).finish();\n        const encodedResponse = await this.handleAgentCommunication(AgentMessageType.GET_SECRET, nodePath, request);\n        const subMessage = (_a = encodedResponse.find((r) => r.type == AgentMessageType.GET_SECRET)) === null || _a === void 0 ? void 0 : _a.subMessage;\n        if (!subMessage) {\n            throw Error('agent did not respond');\n        }\n        const { secret } = GetSecretResponseMessage.decode(subMessage);\n        return Buffer.from(secret);\n    }\n    async updateSecret(nodePath, vaultName, secretName, secret) {\n        var _a;\n        let request;\n        if (typeof secret == 'string') {\n            request = UpdateSecretRequestMessage.encode({ vaultName, secretName, secretPath: secret }).finish();\n        }\n        else {\n            request = UpdateSecretRequestMessage.encode({ vaultName, secretName, secretContent: secret }).finish();\n        }\n        const encodedResponse = await this.handleAgentCommunication(AgentMessageType.UPDATE_SECRET, nodePath, request);\n        const subMessage = (_a = encodedResponse.find((r) => r.type == AgentMessageType.UPDATE_SECRET)) === null || _a === void 0 ? void 0 : _a.subMessage;\n        if (!subMessage) {\n            throw Error('agent did not respond');\n        }\n        const { successful } = UpdateSecretResponseMessage.decode(subMessage);\n        return successful;\n    }\n    ///////////////////\n    // Agent control //\n    ///////////////////\n    async getAgentStatus() {\n        var _a;\n        try {\n            const encodedResponse = await this.handleAgentCommunication(AgentMessageType.STATUS);\n            const subMessage = (_a = encodedResponse.find((r) => r.type == AgentMessageType.STATUS)) === null || _a === void 0 ? void 0 : _a.subMessage;\n            if (!subMessage) {\n                throw Error('agent did not respond');\n            }\n            const status = Buffer.from(subMessage).toString();\n            return status;\n        }\n        catch (err) {\n            if (err.toString().match(/ECONNRESET|ENOENT|ECONNRESET/)) {\n                return 'stopped';\n            }\n            throw err;\n        }\n    }\n    async stopAgent() {\n        try {\n            // Tell it to start shutting and wait for response\n            await this.handleAgentCommunication(AgentMessageType.STOP_AGENT);\n            return true;\n        }\n        catch (err) {\n            return (await this.getAgentStatus()) != 'online';\n        }\n    }\n}\nexports.default = PolykeyClient;\n","module.exports = require(\"../../proto/js/Agent\");","\"use strict\";\nvar __importDefault = (this && this.__importDefault) || function (mod) {\n    return (mod && mod.__esModule) ? mod : { \"default\": mod };\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nconst os_1 = __importDefault(require(\"os\"));\nconst fs_1 = __importDefault(require(\"fs\"));\nconst path_1 = __importDefault(require(\"path\"));\nconst kbpgp_1 = __importDefault(require(\"kbpgp\"));\nconst crypto_1 = __importDefault(require(\"crypto\"));\nconst util_1 = require(\"util\");\nclass KeyManager {\n    constructor(polyKeyPath = `${os_1.default.homedir()}/.polykey`, fileSystem, useWebWorkers = false, workerPool) {\n        this.primaryKeyPair = { private: null, public: null };\n        this.metadata = {\n            privateKeyPath: null,\n            publicKeyPath: null,\n            pkiKeyPath: null,\n            pkiCertPath: null,\n            caCertPath: null,\n        };\n        /////////\n        // PKI //\n        /////////\n        this.pkiInfo = { key: null, cert: null, caCert: null };\n        this.useWebWorkers = useWebWorkers;\n        this.workerPool = workerPool;\n        this.derivedKeys = new Map();\n        this.fileSystem = fileSystem;\n        // Load key manager metadata\n        this.polykeyPath = polyKeyPath;\n        this.keypairPath = path_1.default.join(polyKeyPath, '.keys');\n        if (!this.fileSystem.existsSync(this.keypairPath)) {\n            this.fileSystem.mkdirSync(this.keypairPath, { recursive: true });\n        }\n        this.metadataPath = path_1.default.join(this.keypairPath, 'metadata');\n        this.derivedKeysPath = path_1.default.join(this.keypairPath, 'derived-keys');\n        this.loadMetadata();\n        // Load keys if they were provided\n        if (this.metadata.privateKeyPath && this.metadata.publicKeyPath) {\n            // Load files into memory\n            this.loadKeyPair(this.metadata.publicKeyPath, this.metadata.privateKeyPath);\n        }\n        /////////\n        // PKI //\n        /////////\n        // Load pki keys and certs\n        if (this.metadata.pkiKeyPath) {\n            this.pkiInfo.key = fs_1.default.readFileSync(this.metadata.pkiKeyPath);\n        }\n        if (this.metadata.pkiCertPath) {\n            this.pkiInfo.cert = fs_1.default.readFileSync(this.metadata.pkiCertPath);\n        }\n        if (this.metadata.caCertPath) {\n            this.pkiInfo.caCert = fs_1.default.readFileSync(this.metadata.caCertPath);\n        }\n        this.loadPKIInfo(this.pkiInfo.key, this.pkiInfo.cert, this.pkiInfo.caCert, true);\n    }\n    get identityLoaded() {\n        return this.primaryIdentity ? true : false;\n    }\n    /**\n     * Generates a new assymetric key pair (publicKey and privateKey).\n     * @param name Name of keypair owner\n     * @param email Email of keypair owner\n     * @param passphrase Passphrase to lock the keypair\n     * @param nbits Size of the new keypair\n     * @param replacePrimary If true, the generated keypair becomes the new primary identity of the key manager\n     * @param progressCallback A progress hook for keypair generation\n     */\n    async generateKeyPair(name, email, passphrase, nbits = 4096, replacePrimary = false, progressCallback) {\n        // kbpgp doesn't seem to work for small nbits so set a minimum of 1024\n        if (nbits < 1024) {\n            throw Error('nbits must be greater than 1024 for keypair generation');\n        }\n        // Define options\n        const flags = kbpgp_1.default['const'].openpgp;\n        const params = {\n            asp: progressCallback ? new kbpgp_1.default.ASP({ progress_hook: progressCallback }) : undefined,\n            userid: `${name} <${email}>`,\n            primary: {\n                nbits: nbits,\n                flags: flags.certify_keys | flags.sign_data | flags.auth | flags.encrypt_comm | flags.encrypt_storage,\n                expire_in: 0,\n            },\n            subkeys: [],\n        };\n        const identity = await util_1.promisify(kbpgp_1.default.KeyManager.generate)(params);\n        await util_1.promisify(identity.sign.bind(identity))({});\n        // Export pub key first\n        const publicKey = await util_1.promisify(identity.export_pgp_public.bind(identity))({});\n        // Finally export priv key\n        const privateKey = await util_1.promisify(identity.export_pgp_private.bind(identity))({ passphrase: passphrase });\n        // Resolve to parent promise\n        const keypair = { private: privateKey, public: publicKey };\n        if (replacePrimary) {\n            // Set the new keypair\n            this.primaryKeyPair = keypair;\n            // Set the new identity\n            this.primaryIdentity = identity;\n            // Overwrite in memory\n            const privateKeyPath = path_1.default.join(this.keypairPath, 'private_key');\n            const publicKeyPath = path_1.default.join(this.keypairPath, 'public_key');\n            await this.fileSystem.promises.writeFile(privateKeyPath, keypair.private);\n            await this.fileSystem.promises.writeFile(publicKeyPath, keypair.public);\n            // Set metadata\n            this.metadata.privateKeyPath = privateKeyPath;\n            this.metadata.publicKeyPath = publicKeyPath;\n            this.writeMetadata();\n        }\n        return keypair;\n    }\n    /**\n     * Get the primary keypair\n     */\n    getKeyPair() {\n        return this.primaryKeyPair;\n    }\n    /**\n     * Determines whether public key is loaded or not\n     */\n    hasPublicKey() {\n        return this.primaryKeyPair.public ? true : false;\n    }\n    /**\n     * Get the public key of the primary keypair\n     */\n    getPublicKey() {\n        if (!this.primaryKeyPair.public) {\n            throw Error('Public key does not exist in memory');\n        }\n        return this.primaryKeyPair.public;\n    }\n    /**\n     * Get the private key of the primary keypair\n     */\n    getPrivateKey() {\n        if (!this.primaryKeyPair.private) {\n            throw Error('Private key does not exist in memory');\n        }\n        return this.primaryKeyPair.private;\n    }\n    /**\n     * Loads the keypair into the key manager as the primary identity\n     * @param publicKey Public Key\n     * @param privateKey Private Key\n     */\n    loadKeyPair(publicKey, privateKey) {\n        this.loadPrivateKey(privateKey);\n        this.loadPublicKey(publicKey);\n    }\n    /**\n     * Loads the private key into the primary keypair\n     * @param privateKey Private Key\n     */\n    loadPrivateKey(privateKey) {\n        let keyBuffer;\n        if (typeof privateKey === 'string') {\n            keyBuffer = this.fileSystem.readFileSync(privateKey);\n            this.metadata.privateKeyPath = privateKey;\n            this.writeMetadata();\n        }\n        else {\n            keyBuffer = privateKey;\n        }\n        this.primaryKeyPair.private = keyBuffer.toString();\n    }\n    /**\n     * Loads the public key into the primary keypair\n     * @param publicKey Public Key\n     */\n    loadPublicKey(publicKey) {\n        let keyBuffer;\n        if (typeof publicKey === 'string') {\n            keyBuffer = this.fileSystem.readFileSync(publicKey);\n            this.metadata.publicKeyPath = publicKey;\n            this.writeMetadata();\n        }\n        else {\n            keyBuffer = publicKey;\n        }\n        this.primaryKeyPair.public = keyBuffer.toString();\n    }\n    /**\n     * Loads the primary identity into the key manager from the existing keypair\n     * @param passphrase Passphrase to unlock the private key\n     */\n    async unlockIdentity(passphrase) {\n        const publicKey = this.getPublicKey();\n        const privateKey = this.getPrivateKey();\n        const identity = await util_1.promisify(kbpgp_1.default.KeyManager.import_from_armored_pgp)({ armored: publicKey });\n        await util_1.promisify(identity.merge_pgp_private.bind(identity))({ armored: privateKey });\n        if (identity.is_pgp_locked.bind(identity)()) {\n            await util_1.promisify(identity.unlock_pgp.bind(identity))({ passphrase: passphrase });\n        }\n        this.primaryIdentity = identity;\n    }\n    /**\n     * Export the primary private key to a specified location\n     * @param path Destination path\n     */\n    exportPrivateKey(path) {\n        this.fileSystem.writeFileSync(path, this.primaryKeyPair.private);\n        this.metadata.privateKeyPath = path;\n        this.writeMetadata();\n    }\n    /**\n     * Export the primary public key to a specified location\n     * @param path Destination path\n     */\n    exportPublicKey(path) {\n        this.fileSystem.writeFileSync(path, this.primaryKeyPair.public);\n        this.metadata.publicKeyPath = path;\n        this.writeMetadata();\n    }\n    /**\n     * Asynchronously Generates a new symmetric key and stores it in the key manager\n     * @param name Unique name of the generated key\n     * @param passphrase Passphrase to derive the key from\n     * @param storeKey Whether to store the key in the key manager\n     */\n    async generateKey(name, passphrase, storeKey = true) {\n        const salt = crypto_1.default.randomBytes(32);\n        const key = await util_1.promisify(crypto_1.default.pbkdf2)(passphrase, salt, 10000, 256 / 8, 'sha256');\n        if (storeKey) {\n            this.derivedKeys[name] = key;\n            await this.writeMetadata();\n        }\n        return key;\n    }\n    /**\n     * Deletes a derived symmetric key from the key manager\n     * @param name Name of the key to be deleted\n     */\n    async deleteKey(name) {\n        const successful = delete this.derivedKeys[name];\n        await this.writeMetadata();\n        return successful;\n    }\n    /**\n     * List all keys in the current keymanager\n     */\n    listKeys() {\n        return Object.keys(this.derivedKeys);\n    }\n    /**\n     * Synchronously imports an existing key from file or Buffer\n     * @param name Unique name of the imported key\n     * @param key Key to be imported\n     */\n    importKeySync(name, key) {\n        if (typeof key === 'string') {\n            this.derivedKeys[name] = this.fileSystem.readFileSync(key);\n        }\n        else {\n            this.derivedKeys[name] = key;\n        }\n    }\n    /**\n     * Asynchronously imports an existing key from file or Buffer\n     * @param name Unique name of the imported key\n     * @param key Key to be imported\n     */\n    async importKey(name, key) {\n        if (typeof key === 'string') {\n            this.derivedKeys[name] = await this.fileSystem.promises.readFile(key);\n        }\n        else {\n            this.derivedKeys[name] = key;\n        }\n    }\n    /**\n     * Synchronously exports an existing key from file or Buffer\n     * @param name Name of the key to be exported\n     * @param dest Destination path\n     * @param createPath If set to true, the path is recursively created\n     */\n    exportKeySync(name, dest, createPath) {\n        if (!this.derivedKeys.has(name)) {\n            throw Error(`There is no key loaded for name: ${name}`);\n        }\n        if (createPath) {\n            this.fileSystem.mkdirSync(path_1.default.dirname(dest), { recursive: true });\n        }\n        this.fileSystem.writeFileSync(dest, this.derivedKeys[name]);\n    }\n    /**\n     * Asynchronously exports an existing key from file or Buffer\n     * @param name Name of the key to be exported\n     * @param dest Destination path\n     * @param createPath If set to true, the path is recursively created\n     */\n    async exportKey(name, dest, createPath) {\n        if (!this.derivedKeys.has(name)) {\n            throw Error(`There is no key loaded for name: ${name}`);\n        }\n        if (createPath) {\n            await this.fileSystem.promises.mkdir(path_1.default.dirname(dest), { recursive: true });\n        }\n        await this.fileSystem.promises.writeFile(dest, this.derivedKeys[name]);\n    }\n    /**\n     * Loads an identity from the given public key\n     * @param publicKey Buffer containing the public key\n     */\n    async getIdentityFromPublicKey(publicKey) {\n        const identity = await util_1.promisify(kbpgp_1.default.KeyManager.import_from_armored_pgp)({ armored: publicKey });\n        return identity;\n    }\n    /**\n     * Loads an identity from the given private key\n     * @param publicKey Buffer containing the public key\n     */\n    async getIdentityFromPrivateKey(privateKey, passphrase) {\n        const identity = await util_1.promisify(kbpgp_1.default.KeyManager.import_from_armored_pgp)({ armored: privateKey });\n        if (identity.is_pgp_locked()) {\n            await util_1.promisify(identity.unlock_pgp.bind(identity))({ passphrase });\n        }\n        return identity;\n    }\n    /**\n     * Signs the given data with the provided key or the primary key if none is specified\n     * @param data Buffer or file containing the data to be signed\n     * @param privateKey Buffer containing the key to sign with. Defaults to primary private key if no key is given.\n     * @param keyPassphrase Required if privateKey is provided.\n     */\n    async signData(data, privateKey, keyPassphrase) {\n        let resolvedIdentity;\n        if (privateKey) {\n            if (!keyPassphrase) {\n                throw Error('passphrase for private key was not provided');\n            }\n            resolvedIdentity = await this.getIdentityFromPrivateKey(privateKey, keyPassphrase);\n        }\n        else if (this.primaryIdentity) {\n            resolvedIdentity = this.primaryIdentity;\n        }\n        else {\n            throw Error('key pair is not loaded');\n        }\n        if (this.useWebWorkers && this.workerPool) {\n            const workerResponse = await this.workerPool.queue(async (workerCrypto) => {\n                return await workerCrypto.signData(data, resolvedIdentity);\n            });\n            return workerResponse;\n        }\n        else {\n            const params = {\n                msg: data.toString(),\n                sign_with: resolvedIdentity,\n            };\n            const result_string = await util_1.promisify(kbpgp_1.default.box)(params);\n            return Buffer.from(result_string);\n        }\n    }\n    /**\n     * Signs the given file with the provided key or the primary key if none is specified\n     * @param filePath Path to file containing the data to be signed\n     * @param privateKey The key to sign with. Defaults to primary public key if no key is given.\n     * @param keyPassphrase Required if privateKey is provided.\n     */\n    async signFile(filePath, privateKey, keyPassphrase) {\n        // Get key if provided\n        let keyBuffer;\n        if (privateKey) {\n            if (typeof privateKey === 'string') {\n                // Path\n                // Read in from fs\n                keyBuffer = this.fileSystem.readFileSync(privateKey);\n            }\n            else {\n                // Buffer\n                keyBuffer = privateKey;\n            }\n        }\n        // Read file into buffer\n        const buffer = this.fileSystem.readFileSync(filePath);\n        // Sign the buffer\n        const signedBuffer = await this.signData(buffer, keyBuffer, keyPassphrase);\n        // Write buffer to signed file\n        const signedPath = `${filePath}.sig`;\n        this.fileSystem.writeFileSync(signedPath, signedBuffer);\n        return signedPath;\n    }\n    /**\n     * Verifies the given data with the provided key or the primary key if none is specified\n     * @param data Buffer or file containing the data to be verified\n     * @param publicKey Buffer containing the key to verify with. Defaults to primary public key if no key is given.\n     */\n    async verifyData(data, publicKey) {\n        const ring = new kbpgp_1.default.keyring.KeyRing();\n        let resolvedIdentity;\n        if (publicKey) {\n            resolvedIdentity = await this.getIdentityFromPublicKey(publicKey);\n        }\n        else if (this.primaryIdentity) {\n            resolvedIdentity = this.primaryIdentity;\n        }\n        else {\n            throw Error('key pair is not loaded');\n        }\n        ring.add_key_manager(resolvedIdentity);\n        if (this.useWebWorkers && this.workerPool) {\n            const workerResponse = await this.workerPool.queue(async (workerCrypto) => {\n                return await workerCrypto.verifyData(data, resolvedIdentity);\n            });\n            return workerResponse;\n        }\n        else {\n            const params = {\n                armored: data,\n                keyfetch: ring,\n            };\n            const literals = await util_1.promisify(kbpgp_1.default.unbox)(params);\n            // Get the identity that signed the data if any\n            let dataSigner = literals[0].get_data_signer();\n            // Retrieve the key manager associated with that data signer\n            let keyManager;\n            if (dataSigner) {\n                keyManager = dataSigner.get_key_manager();\n            }\n            // If we know the pgp finger print then we say the data is verified.\n            // Otherwise it is unverified.\n            if (keyManager) {\n                if (keyManager.get_pgp_fingerprint()) {\n                    return true;\n                }\n                else {\n                    return false;\n                }\n            }\n            else {\n                return false;\n            }\n        }\n    }\n    /**\n     * Verifies the given file with the provided key or the primary key if none is specified\n     * @param filePath Path to file containing the data to be verified\n     * @param publicKey Buffer containing the key to verify with. Defaults to primary public key if no key is given.\n     */\n    async verifyFile(filePath, publicKey) {\n        // Get key if provided\n        let keyBuffer;\n        if (publicKey) {\n            if (typeof publicKey === 'string') {\n                // Path\n                // Read in from fs\n                keyBuffer = this.fileSystem.readFileSync(publicKey);\n            }\n            else {\n                // Buffer\n                keyBuffer = publicKey;\n            }\n        }\n        // Read in file buffer and signature\n        const fileBuffer = this.fileSystem.readFileSync(filePath);\n        const isVerified = await this.verifyData(fileBuffer, keyBuffer);\n        return isVerified;\n    }\n    /**\n     * Encrypts the given data for a specific public key\n     * @param data The data to be encrypted\n     * @param publicKey The key to encrypt for\n     */\n    async encryptData(data, publicKey) {\n        let resolvedIdentity;\n        if (publicKey) {\n            resolvedIdentity = await this.getIdentityFromPublicKey(publicKey);\n        }\n        else if (this.primaryIdentity) {\n            resolvedIdentity = this.primaryIdentity;\n        }\n        else {\n            throw Error(`Identity could not be resolved for encrypting`);\n        }\n        if (this.useWebWorkers && this.workerPool) {\n            const workerResponse = await this.workerPool.queue(async (workerCrypto) => {\n                return await workerCrypto.encryptData(data, resolvedIdentity);\n            });\n            return workerResponse;\n        }\n        else {\n            const params = {\n                msg: data,\n                encrypt_for: resolvedIdentity,\n            };\n            const result_string = await util_1.promisify(kbpgp_1.default.box)(params);\n            return result_string;\n        }\n    }\n    /**\n     * Encrypts the given file for a specific public key\n     * @param filePath Path to file containing the data to be encrypted\n     * @param publicKey Buffer containing the key to verify with. Defaults to primary public key if no key is given.\n     */\n    async encryptFile(filePath, publicKey) {\n        // Get key if provided\n        let keyBuffer;\n        if (publicKey) {\n            if (typeof publicKey === 'string') {\n                // Read in from fs\n                keyBuffer = this.fileSystem.readFileSync(publicKey);\n            }\n            else {\n                // Buffer\n                keyBuffer = publicKey;\n            }\n        }\n        // Read file into buffer\n        const buffer = this.fileSystem.readFileSync(filePath);\n        // Encrypt the buffer\n        const encryptedBuffer = await this.encryptData(buffer, keyBuffer);\n        // Write buffer to encrypted file\n        this.fileSystem.writeFileSync(filePath, encryptedBuffer);\n        return filePath;\n    }\n    /**\n     * Decrypts the given data with the provided key or the primary key if none is given\n     * @param data The data to be decrypted\n     * @param privateKey The key to decrypt with. Defaults to primary private key if no key is given.\n     * @param keyPassphrase Required if privateKey is provided.\n     */\n    async decryptData(data, privateKey, keyPassphrase) {\n        var ring = new kbpgp_1.default.keyring.KeyRing();\n        let resolvedIdentity;\n        if (privateKey) {\n            if (keyPassphrase) {\n                resolvedIdentity = await this.getIdentityFromPrivateKey(privateKey, keyPassphrase);\n            }\n            else {\n                throw Error('A key passphrase must be supplied if a privateKey is specified');\n            }\n        }\n        else if (this.primaryIdentity) {\n            resolvedIdentity = this.primaryIdentity;\n        }\n        else {\n            throw Error('no identity available for decrypting');\n        }\n        if (this.useWebWorkers && this.workerPool) {\n            const workerResponse = await this.workerPool.queue(async (workerCrypto) => {\n                return await workerCrypto.decryptData(data, resolvedIdentity);\n            });\n            return workerResponse;\n        }\n        else {\n            ring.add_key_manager(resolvedIdentity);\n            const params = {\n                armored: data.toString(),\n                keyfetch: ring,\n            };\n            const literals = await util_1.promisify(kbpgp_1.default.unbox)(params);\n            const decryptedData = Buffer.from(literals[0].toString());\n            return decryptedData;\n        }\n    }\n    /**\n     * Decrypts the given file with the provided key or the primary key if none is given\n     * @param filePath Path to file containing the data to be decrypted\n     * @param privateKey The key to decrypt with. Defaults to primary private key if no key is given.\n     * @param keyPassphrase Required if privateKey is provided.\n     */\n    async decryptFile(filePath, privateKey, keyPassphrase) {\n        // Get key if provided\n        let keyBuffer;\n        if (privateKey) {\n            if (typeof privateKey === 'string') {\n                // Read in from fs\n                keyBuffer = this.fileSystem.readFileSync(privateKey);\n            }\n            else {\n                // Buffer\n                keyBuffer = privateKey;\n            }\n        }\n        // Read in file buffer\n        const fileBuffer = this.fileSystem.readFileSync(filePath);\n        // Decrypt file buffer\n        const decryptedData = await this.decryptData(fileBuffer, keyBuffer, keyPassphrase);\n        // Write buffer to decrypted file\n        this.fileSystem.writeFileSync(filePath, decryptedData);\n        return filePath;\n    }\n    /////////\n    // PKI //\n    /////////\n    get PKIInfo() {\n        return this.pkiInfo;\n    }\n    loadPKIInfo(key, cert, caCert, writeToFile = false) {\n        if (key) {\n            this.pkiInfo.key = key;\n        }\n        if (cert) {\n            this.pkiInfo.cert = cert;\n        }\n        if (caCert) {\n            this.pkiInfo.caCert = caCert;\n        }\n        if (writeToFile) {\n            // Store in the metadata path folder\n            const storagePath = path_1.default.dirname(this.metadataPath);\n            if (key) {\n                this.metadata.pkiKeyPath = path_1.default.join(storagePath, 'pki_private_key');\n                fs_1.default.writeFileSync(this.metadata.pkiKeyPath, key);\n            }\n            if (cert) {\n                this.metadata.pkiCertPath = path_1.default.join(storagePath, 'pki_cert');\n                fs_1.default.writeFileSync(this.metadata.pkiCertPath, cert);\n            }\n            if (caCert) {\n                this.metadata.caCertPath = path_1.default.join(storagePath, 'ca_cert');\n                fs_1.default.writeFileSync(this.metadata.caCertPath, caCert);\n            }\n        }\n    }\n    /* ============ HELPERS =============== */\n    /**\n     * Get the key for a given name\n     * @param name The unique name of the desired key\n     */\n    getKey(name) {\n        return this.derivedKeys[name];\n    }\n    /**\n     * Determines if the Key Manager has a certain key\n     * @param name The unique name of the desired key\n     */\n    hasKey(name) {\n        if (this.derivedKeys[name]) {\n            return true;\n        }\n        return false;\n    }\n    async writeMetadata() {\n        const metadata = JSON.stringify(this.metadata);\n        this.fileSystem.writeFileSync(this.metadataPath, metadata);\n        // Store the keys if identity is loaded\n        if (this.identityLoaded) {\n            const derivedKeys = JSON.stringify(this.derivedKeys);\n            const encryptedMetadata = await this.encryptData(Buffer.from(derivedKeys));\n            await this.fileSystem.promises.writeFile(this.derivedKeysPath, encryptedMetadata);\n        }\n    }\n    async loadMetadata() {\n        // Check if file exists\n        if (this.fileSystem.existsSync(this.metadataPath)) {\n            const metadata = this.fileSystem.readFileSync(this.metadataPath).toString();\n            this.metadata = JSON.parse(metadata);\n            if (this.identityLoaded && this.fileSystem.existsSync(this.derivedKeysPath)) {\n                const encryptedMetadata = this.fileSystem.readFileSync(this.derivedKeysPath);\n                const metadata = (await this.decryptData(encryptedMetadata)).toString();\n                const derivedKeys = JSON.parse(metadata);\n                for (const key of Object.keys(derivedKeys)) {\n                    this.derivedKeys[key] = Buffer.from(derivedKeys[key]);\n                }\n            }\n        }\n    }\n}\nexports.default = KeyManager;\n","module.exports = require(\"kbpgp\");","module.exports = require(\"util\");","\"use strict\";\nvar __importDefault = (this && this.__importDefault) || function (mod) {\n    return (mod && mod.__esModule) ? mod : { \"default\": mod };\n};\nvar __importStar = (this && this.__importStar) || function (mod) {\n    if (mod && mod.__esModule) return mod;\n    var result = {};\n    if (mod != null) for (var k in mod) if (Object.hasOwnProperty.call(mod, k)) result[k] = mod[k];\n    result[\"default\"] = mod;\n    return result;\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nconst os_1 = __importDefault(require(\"os\"));\nconst path_1 = __importDefault(require(\"path\"));\nconst grpc = __importStar(require(\"@grpc/grpc-js\"));\nconst GitFrontend_1 = __importDefault(require(\"../git/GitFrontend\"));\nconst GitBackend_1 = __importDefault(require(\"../git/GitBackend\"));\nconst Peer_1 = require(\"../../../proto/js/Peer\");\nconst utils_1 = require(\"../utils\");\nconst PeerInfo_1 = __importStar(require(\"../peers/PeerInfo\"));\nconst MulticastBroadcaster_1 = __importDefault(require(\"../peers/MulticastBroadcaster\"));\nconst Git_grpc_pb_1 = require(\"../../../proto/compiled/Git_grpc_pb\");\nconst Git_pb_1 = require(\"../../../proto/compiled/Git_pb\");\nconst keybaseDiscovery = {\n    name: 'Keybase',\n    findUser: async (handle, service) => {\n        const url = `https://keybase.io/_/api/1.0/user/lookup.json?${service}=${handle}`;\n        try {\n            const response = await fetch(url);\n            const data = await response.json();\n            const pubKey = data.them[0].public_keys.primary.bundle;\n            return pubKey;\n        }\n        catch (err) {\n            throw Error(`User was not found: ${err.message}`);\n        }\n    },\n};\nclass PeerManager {\n    constructor(polykeyPath = `${os_1.default.homedir()}/.polykey`, fileSystem, keyManager, vaultManager, peerInfo, socialDiscoveryServices = []) {\n        var _a;\n        this.metadata = { localPeerInfo: null };\n        this.serverStarted = false;\n        this.fileSystem = fileSystem;\n        this.fileSystem.mkdirSync(polykeyPath, { recursive: true });\n        this.metadataPath = path_1.default.join(polykeyPath, '.peerMetadata');\n        // Set given variables\n        this.keyManager = keyManager;\n        this.socialDiscoveryServices = socialDiscoveryServices;\n        // Load metadata with peer info\n        this.loadMetadata();\n        // Load peer store and local peer info\n        if (peerInfo) {\n            this.localPeerInfo = peerInfo;\n            this.writeMetadata();\n        }\n        else if (this.metadata.localPeerInfo) {\n            this.localPeerInfo = this.metadata.localPeerInfo;\n        }\n        else if (this.keyManager.hasPublicKey()) {\n            this.localPeerInfo = new PeerInfo_1.default(this.keyManager.getPublicKey());\n        }\n        this.peerStore = new Map();\n        this.socialDiscoveryServices = [];\n        this.socialDiscoveryServices.push(keybaseDiscovery);\n        for (const service of socialDiscoveryServices) {\n            this.socialDiscoveryServices.push(service);\n        }\n        this.multicastBroadcaster = new MulticastBroadcaster_1.default(this.addPeer, this.localPeerInfo, this.keyManager);\n        this.peerConnections = new Map();\n        /////////////////\n        // GRPC Server //\n        /////////////////\n        this.gitBackend = new GitBackend_1.default(polykeyPath, ((vaultName) => vaultManager.getVault(vaultName).EncryptedFS).bind(vaultManager));\n        this.server = new grpc.Server();\n        // Add service\n        this.server.addService(Git_grpc_pb_1.GitServerService, {\n            requestInfo: this.requestInfo.bind(this),\n            requestPack: this.requestPack.bind(this),\n        });\n        // Create the server credentials. SSL only if ca cert exists\n        const pkiInfo = this.keyManager.PKIInfo;\n        if (pkiInfo.caCert && pkiInfo.cert && pkiInfo.key) {\n            this.credentials = grpc.ServerCredentials.createSsl(pkiInfo.caCert, [\n                {\n                    private_key: pkiInfo.key,\n                    cert_chain: pkiInfo.cert,\n                },\n            ], true);\n        }\n        else {\n            this.credentials = grpc.ServerCredentials.createInsecure();\n        }\n        this.server.bindAsync(`0.0.0.0:${(_a = process.env.PK_PORT) !== null && _a !== void 0 ? _a : 0}`, this.credentials, async (err, boundPort) => {\n            if (err) {\n                throw err;\n            }\n            else {\n                const address = new PeerInfo_1.Address('localhost', boundPort.toString());\n                this.server.start();\n                while (!this.localPeerInfo) {\n                    await new Promise((r, _) => setTimeout(() => r(), 1000));\n                }\n                this.localPeerInfo.connect(address);\n                this.serverStarted = true;\n            }\n        });\n    }\n    async requestInfo(call, callback) {\n        const infoRequest = call.request;\n        const vaultName = infoRequest.getVaultname();\n        const infoReply = new Git_pb_1.InfoReply();\n        infoReply.setVaultname(vaultName);\n        infoReply.setBody(await this.gitBackend.handleInfoRequest(vaultName));\n        callback(null, infoReply);\n    }\n    async requestPack(call, callback) {\n        const packRequest = call.request;\n        const vaultName = packRequest.getVaultname();\n        const body = Buffer.from(packRequest.getBody_asB64(), 'base64');\n        const reply = new Git_pb_1.PackReply();\n        reply.setVaultname(vaultName);\n        reply.setBody(await this.gitBackend.handlePackRequest(vaultName, body));\n        callback(null, reply);\n    }\n    ////////////////\n    // Peer store //\n    ////////////////\n    /**\n     * Get the peer info of the current keynode\n     */\n    getLocalPeerInfo() {\n        return this.localPeerInfo;\n    }\n    /**\n     * Set the address of the active server\n     * @param adress Address of active server\n     */\n    connectLocalPeerInfo(address) {\n        this.localPeerInfo.connect(address);\n    }\n    /**\n     * Add a peer's info to the peerStore\n     * @param peerInfo Info of the peer to be added\n     */\n    addPeer(peerInfo) {\n        this.peerStore.set(peerInfo.publicKey, peerInfo);\n    }\n    /**\n     * Retrieves a peer for the given public key\n     * @param publicKey Public key of the desired peer\n     */\n    getPeer(publicKey) {\n        var _a;\n        return (_a = this.peerStore.get(publicKey)) !== null && _a !== void 0 ? _a : null;\n    }\n    /**\n     * Determines if the peerStore contains the desired peer\n     * @param publicKey Public key of the desired peer\n     */\n    hasPeer(pubKey) {\n        return this.peerStore.has(pubKey);\n    }\n    //////////////////////\n    // Social discovery //\n    //////////////////////\n    /**\n     * Finds an existing peer using multicast peer discovery\n     * @param publicKey Public key of the desired peer\n     */\n    async findPubKey(publicKey) {\n        return new Promise((resolve, reject) => {\n            this.multicastBroadcaster.requestPeerContact(publicKey);\n            this.multicastBroadcaster.on('found', (peerInfo) => {\n                if (peerInfo.publicKey == publicKey) {\n                    resolve(peerInfo);\n                }\n            });\n            this.multicastBroadcaster.on('timeout', (timedOutPubKey) => {\n                if (timedOutPubKey == publicKey) {\n                    reject('The broadcaster stopped looking');\n                }\n            });\n        });\n    }\n    /**\n     * Finds an existing peer given a social service and handle\n     * @param handle Username or handle of the user (e.g. @john-smith)\n     * @param service Service on which to search for the user (e.g. github)\n     */\n    async findSocialUser(handle, service) {\n        const tasks = [];\n        for (const socialDiscovery of this.socialDiscoveryServices) {\n            try {\n                tasks.push(socialDiscovery.findUser(handle, service));\n            }\n            catch (error) {\n                console.log(`Could not find user on this discovery service: ${socialDiscovery.name}`);\n            }\n        }\n        const pubKeyOrFail = await utils_1.firstPromiseFulfilled(tasks);\n        if (pubKeyOrFail.length > 1) {\n            throw Error('Could not find public key from services');\n        }\n        const pubKeyFound = pubKeyOrFail[0];\n        const peerInfo = await this.findPubKey(pubKeyFound);\n        return peerInfo;\n    }\n    ///////////////////////\n    // Peers Connections //\n    ///////////////////////\n    /**\n     * Get a secure connection to the peer\n     * @param peer Public key of an existing peer or address of new peer\n     */\n    connectToPeer(peer) {\n        var _a;\n        // Throw error if trying to connect to self\n        if (peer == this.localPeerInfo.connectedAddr || peer == this.localPeerInfo.publicKey) {\n            throw Error('Cannot connect to self');\n        }\n        let address;\n        if (typeof peer == 'string') {\n            const existingConnection = this.peerConnections.get(peer);\n            if (existingConnection) {\n                return existingConnection;\n            }\n            const peerAddress = (_a = this.getPeer(peer)) === null || _a === void 0 ? void 0 : _a.connectedAddr;\n            if (peerAddress) {\n                address = peerAddress;\n            }\n            else {\n                throw Error('Peer does not exist in peer store');\n            }\n        }\n        else {\n            address = peer;\n        }\n        const conn = new GitFrontend_1.default(address, this.keyManager);\n        if (typeof peer == 'string') {\n            this.peerConnections.set(peer, conn);\n        }\n        return conn;\n    }\n    /* ============ HELPERS =============== */\n    writeMetadata() {\n        var _a;\n        const peerInfo = this.localPeerInfo;\n        const metadata = Peer_1.peer.PeerInfoMessage.encode({\n            addresses: peerInfo.AdressStringList,\n            connectedAddr: (_a = peerInfo.connectedAddr) === null || _a === void 0 ? void 0 : _a.toString(),\n            pubKey: peerInfo.publicKey,\n        }).finish();\n        this.fileSystem.writeFileSync(this.metadataPath, metadata);\n    }\n    loadMetadata() {\n        // Check if file exists\n        if (this.fileSystem.existsSync(this.metadataPath)) {\n            const metadata = this.fileSystem.readFileSync(this.metadataPath);\n            const { addresses, connectedAddr, pubKey } = Peer_1.peer.PeerInfoMessage.decode(metadata);\n            this.localPeerInfo = new PeerInfo_1.default(pubKey, addresses, connectedAddr);\n        }\n    }\n}\nexports.default = PeerManager;\n","\"use strict\";\nvar __importStar = (this && this.__importStar) || function (mod) {\n    if (mod && mod.__esModule) return mod;\n    var result = {};\n    if (mod != null) for (var k in mod) if (Object.hasOwnProperty.call(mod, k)) result[k] = mod[k];\n    result[\"default\"] = mod;\n    return result;\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nconst grpc = __importStar(require(\"@grpc/grpc-js\"));\nconst Git_grpc_pb_1 = require(\"../../../proto/compiled/Git_grpc_pb\");\nconst Git_pb_1 = require(\"../../../proto/compiled/Git_pb\");\n/**\n * Responsible for converting HTTP messages from isomorphic-git into requests and sending them to a specific peer.\n */\nclass GitFrontend {\n    constructor(address, keyManager) {\n        const pkiInfo = keyManager.PKIInfo;\n        if (pkiInfo.caCert && pkiInfo.cert && pkiInfo.key) {\n            this.credentials = grpc.credentials.createSsl(pkiInfo.caCert, pkiInfo.key, pkiInfo.cert);\n        }\n        else {\n            this.credentials = grpc.credentials.createInsecure();\n        }\n        this.client = new Git_grpc_pb_1.GitServerClient(address.toString(), this.credentials);\n    }\n    /**\n     * Requests remote info from the connected peer for the named vault.\n     * @param vaultName Name of the desired vault\n     */\n    async requestInfo(vaultName) {\n        return new Promise((resolve, reject) => {\n            const request = new Git_pb_1.InfoRequest();\n            request.setVaultname(vaultName);\n            this.client.requestInfo(request, function (err, response) {\n                if (err) {\n                    reject(err);\n                }\n                else {\n                    resolve(Buffer.from(response.getBody_asB64(), 'base64'));\n                }\n            });\n        });\n    }\n    /**\n     * Requests a pack from the connected peer for the named vault.\n     * @param vaultName Name of the desired vault\n     */\n    async requestPack(vaultName, body) {\n        return new Promise((resolve, reject) => {\n            const request = new Git_pb_1.PackRequest();\n            request.setVaultname(vaultName);\n            request.setBody(body);\n            this.client.requestPack(request, function (err, response) {\n                if (err) {\n                    reject(err);\n                }\n                else {\n                    resolve(Buffer.from(response.getBody_asB64(), 'base64'));\n                }\n            });\n        });\n    }\n}\nexports.default = GitFrontend;\n","\"use strict\";\nvar __importDefault = (this && this.__importDefault) || function (mod) {\n    return (mod && mod.__esModule) ? mod : { \"default\": mod };\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nconst path_1 = __importDefault(require(\"path\"));\nconst readable_stream_1 = require(\"readable-stream\");\nconst uploadPack_1 = __importDefault(require(\"./upload-pack/uploadPack\"));\nconst GitSideBand_1 = __importDefault(require(\"./side-band/GitSideBand\"));\nconst packObjects_1 = __importDefault(require(\"./pack-objects/packObjects\"));\n// Here is the protocol git outlines for sending pack files over http:\n// https://git-scm.com/docs/pack-protocol/2.17.0\n// https://github.com/git/git/blob/master/Documentation/technical/pack-protocol.txt\n// This should be consulted in developing our upload pack implementation\n// This git backend (as well as HttpDuplex class) is heavily inspired by node-git-server:\n// https://github.com/gabrielcsapo/node-git-server\n// We need someway to notify other agents about what vaults we have based on some type of authorisation because they don't explicitly know about them\nclass GitBackend {\n    constructor(repoDirectoryPath, getFileSystem) {\n        this.repoDirectoryPath = repoDirectoryPath;\n        this.getFileSystem = getFileSystem;\n    }\n    async handleInfoRequest(repoName) {\n        // Only handle upload-pack for now\n        const service = 'upload-pack';\n        const fileSystem = this.getFileSystem(repoName);\n        const responseBuffers = [];\n        if (!fileSystem.existsSync(path_1.default.join(this.repoDirectoryPath, repoName))) {\n            throw Error(`repository does not exist: '${repoName}'`);\n        }\n        responseBuffers.push(Buffer.from(this.createGitPacketLine('# service=git-' + service + '\\n')));\n        responseBuffers.push(Buffer.from('0000'));\n        const buffers = await uploadPack_1.default(fileSystem, path_1.default.join(this.repoDirectoryPath, repoName), undefined, true);\n        const buffersToWrite = buffers !== null && buffers !== void 0 ? buffers : [];\n        responseBuffers.push(...buffersToWrite);\n        return Buffer.concat(responseBuffers);\n    }\n    async handlePackRequest(repoName, body) {\n        // eslint-disable-next-line\n        return new Promise(async (resolve, reject) => {\n            const responseBuffers = [];\n            const fileSystem = this.getFileSystem(repoName);\n            // Check if repo exists\n            if (!fileSystem.existsSync(path_1.default.join(this.repoDirectoryPath, repoName))) {\n                throw Error(`repository does not exist: '${repoName}'`);\n            }\n            if (body.toString().slice(4, 8) == 'want') {\n                const wantedObjectId = body.toString().slice(9, 49);\n                const packResult = await packObjects_1.default(fileSystem, path_1.default.join(this.repoDirectoryPath, repoName), [wantedObjectId], undefined);\n                // This the 'wait for more data' line as I understand it\n                responseBuffers.push(Buffer.from('0008NAK\\n'));\n                // This is to get the side band stuff working\n                const readable = new readable_stream_1.PassThrough();\n                const progressStream = new readable_stream_1.PassThrough();\n                const sideBand = GitSideBand_1.default.mux('side-band-64', readable, packResult.packstream, progressStream, []);\n                sideBand.on('data', (data) => {\n                    responseBuffers.push(data);\n                });\n                sideBand.on('end', () => {\n                    resolve(Buffer.concat(responseBuffers));\n                });\n                sideBand.on('error', (err) => {\n                    reject(err);\n                });\n                // Write progress to the client\n                progressStream.write(Buffer.from('0014progress is at 50%\\n'));\n                progressStream.end();\n            }\n        });\n    }\n    // ============ Helper functions ============ //\n    createGitPacketLine(line) {\n        const hexPrefix = (4 + line.length).toString(16);\n        return Array(4 - hexPrefix.length + 1).join('0') + hexPrefix + line;\n    }\n}\nexports.default = GitBackend;\n","\"use strict\";\nvar __importDefault = (this && this.__importDefault) || function (mod) {\n    return (mod && mod.__esModule) ? mod : { \"default\": mod };\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nconst path_1 = __importDefault(require(\"path\"));\nconst GitPktLine_1 = __importDefault(require(\"./GitPktLine\"));\nconst GitRefManager_1 = __importDefault(require(\"./GitRefManager\"));\nasync function writeRefsAdResponse({ capabilities, refs, symrefs }) {\n    const stream = [];\n    // Compose capabilities string\n    let syms = '';\n    for (const [key, value] of Object.entries(symrefs)) {\n        syms += `symref=${key}:${value} `;\n    }\n    let caps = `\\x00${[...capabilities].join(' ')} ${syms}agent=git/isomorphic-git@1.4.0`;\n    // stream.write(GitPktLine.encode(`# service=${service}\\n`))\n    // stream.write(GitPktLine.flush())\n    // Note: In the edge case of a brand new repo, zero refs (and zero capabilities)\n    // are returned.\n    for (const [key, value] of Object.entries(refs)) {\n        stream.push(GitPktLine_1.default.encode(`${value} ${key}${caps}\\n`));\n        caps = '';\n    }\n    stream.push(GitPktLine_1.default.flush());\n    return stream;\n}\nasync function uploadPack(fileSystem, dir, gitdir = path_1.default.join(dir, '.git'), advertiseRefs = false) {\n    try {\n        if (advertiseRefs) {\n            // Send a refs advertisement\n            const capabilities = ['side-band-64k'];\n            let keys = await GitRefManager_1.default.listRefs(fileSystem, gitdir, 'refs');\n            keys = keys.map((ref) => `refs/${ref}`);\n            const refs = {};\n            keys.unshift('HEAD'); // HEAD must be the first in the list\n            for (const key of keys) {\n                refs[key] = await GitRefManager_1.default.resolve(fileSystem, gitdir, key);\n            }\n            const symrefs = {};\n            symrefs['HEAD'] = await GitRefManager_1.default.resolve(fileSystem, gitdir, 'HEAD', 2);\n            return writeRefsAdResponse({\n                capabilities,\n                refs,\n                symrefs,\n            });\n        }\n    }\n    catch (err) {\n        err.caller = 'git.uploadPack';\n        throw err;\n    }\n}\nexports.default = uploadPack;\n","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nclass GitPackedRefs {\n    constructor(text) {\n        this.refs = new Map();\n        this.parsedConfig = [];\n        if (text) {\n            let key;\n            this.parsedConfig = text\n                .trim()\n                .split('\\n')\n                .map((line) => {\n                if (/^\\s*#/.test(line)) {\n                    return { line: line, comment: true };\n                }\n                const i = line.indexOf(' ');\n                if (line.startsWith('^')) {\n                    // This is a oid for the commit associated with the annotated tag immediately preceding this line.\n                    // Trim off the '^'\n                    const value = line.slice(1);\n                    // The tagname^{} syntax is based on the output of `git show-ref --tags -d`\n                    this.refs.set(key + '^{}', value);\n                    return { line: line, ref: key, peeled: value };\n                }\n                else {\n                    // This is an oid followed by the ref name\n                    const value = line.slice(0, i);\n                    key = line.slice(i + 1);\n                    this.refs.set(key, value);\n                    return { line: line, ref: key, oid: value };\n                }\n            });\n        }\n        return this;\n    }\n    static from(text) {\n        return new GitPackedRefs(text);\n    }\n}\nexports.default = GitPackedRefs;\n","\"use strict\";\nvar __importDefault = (this && this.__importDefault) || function (mod) {\n    return (mod && mod.__esModule) ? mod : { \"default\": mod };\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\n/*\nIf 'side-band' or 'side-band-64k' capabilities have been specified by\nthe client, the server will send the packfile data multiplexed.\n\nEach packet starting with the packet-line length of the amount of data\nthat follows, followed by a single byte specifying the sideband the\nfollowing data is coming in on.\n\nIn 'side-band' mode, it will send up to 999 data bytes plus 1 control\ncode, for a total of up to 1000 bytes in a pkt-line.  In 'side-band-64k'\nmode it will send up to 65519 data bytes plus 1 control code, for a\ntotal of up to 65520 bytes in a pkt-line.\n\nThe sideband byte will be a '1', '2' or a '3'. Sideband '1' will contain\npackfile data, sideband '2' will be used for progress information that the\nclient will generally print to stderr and sideband '3' is used for error\ninformation.\n\nIf no 'side-band' capability was specified, the server will stream the\nentire packfile without multiplexing.\n*/\nconst buffer_1 = require(\"buffer\");\nconst readable_stream_1 = require(\"readable-stream\");\nconst GitPktLine_1 = __importDefault(require(\"../upload-pack/GitPktLine\"));\nfunction splitBuffer(buffer, maxBytes) {\n    const result = [];\n    let index = 0;\n    while (index < buffer.length) {\n        const buf = buffer.slice(index, index + maxBytes);\n        result.push(buf);\n        index += buf.length;\n    }\n    result.push(buffer.slice(index));\n    return result;\n}\nclass GitSideBand {\n    static demux(input) {\n        let read = GitPktLine_1.default.streamReader(input);\n        // And now for the ridiculous side-band or side-band-64k protocol\n        let packetlines = new readable_stream_1.PassThrough();\n        let packfile = new readable_stream_1.PassThrough();\n        let progress = new readable_stream_1.PassThrough();\n        // TODO: Use a proper through stream?\n        const nextBit = async function () {\n            let line = await read();\n            // Skip over flush packets\n            if (line === null)\n                return nextBit();\n            // A made up convention to signal there's no more to read.\n            if (line === true) {\n                packetlines.end();\n                progress.end();\n                packfile.end();\n                return;\n            }\n            // Examine first byte to determine which output \"stream\" to use\n            switch (line[0]) {\n                case 1: // pack data\n                    packfile.write(line.slice(1));\n                    break;\n                case 2: // progress message\n                    progress.write(line.slice(1));\n                    break;\n                case 3: // fatal error message just before stream aborts\n                    // eslint-disable-next-line\n                    const error = line.slice(1);\n                    progress.write(error);\n                    packfile.destroy(new Error(error.toString('utf8')));\n                    return;\n                default:\n                    // Not part of the side-band-64k protocol\n                    packetlines.write(line.slice(0));\n            }\n            // Careful not to blow up the stack.\n            // I think Promises in a tail-call position should be OK.\n            nextBit();\n        };\n        nextBit();\n        return {\n            packetlines,\n            packfile,\n            progress,\n        };\n    }\n    static mux(protocol, // 'side-band' or 'side-band-64k'\n    packetlines, packfile, progress, error) {\n        const MAX_PACKET_LENGTH = protocol === 'side-band-64k' ? 999 : 65519;\n        let output = new readable_stream_1.PassThrough();\n        packetlines.on('data', (data) => {\n            if (data === null) {\n                output.write(GitPktLine_1.default.flush());\n            }\n            else {\n                output.write(GitPktLine_1.default.encode(data));\n            }\n        });\n        let packfileWasEmpty = true;\n        let packfileEnded = false;\n        let progressEnded = false;\n        let errorEnded = true;\n        let goodbye = buffer_1.Buffer.concat([GitPktLine_1.default.encode(buffer_1.Buffer.from('010A', 'hex')), GitPktLine_1.default.flush()]);\n        packfile\n            .on('data', (data) => {\n            packfileWasEmpty = false;\n            const buffers = splitBuffer(data, MAX_PACKET_LENGTH);\n            for (const buffer of buffers) {\n                output.write(GitPktLine_1.default.encode(buffer_1.Buffer.concat([buffer_1.Buffer.from('01', 'hex'), buffer])));\n            }\n        })\n            .on('end', () => {\n            packfileEnded = true;\n            if (!packfileWasEmpty)\n                output.write(goodbye);\n            if (progressEnded && errorEnded)\n                output.end();\n        });\n        progress\n            .on('data', (data) => {\n            const buffers = splitBuffer(data, MAX_PACKET_LENGTH);\n            for (const buffer of buffers) {\n                output.write(GitPktLine_1.default.encode(buffer_1.Buffer.concat([buffer_1.Buffer.from('02', 'hex'), buffer])));\n            }\n        })\n            .on('end', () => {\n            progressEnded = true;\n            if (packfileEnded && errorEnded)\n                output.end();\n        });\n        // error\n        //   .on('data', data => {\n        //     const buffers = splitBuffer(data, MAX_PACKET_LENGTH)\n        //     for (const buffer of buffers) {\n        //       output.write(\n        //         GitPktLine.encode(Buffer.concat([Buffer.from('03', 'hex'), buffer]))\n        //       )\n        //     }\n        //   })\n        //   .on('end', () => {\n        //     errorEnded = true\n        //     if (progressEnded && packfileEnded) output.end()\n        //   })\n        return output;\n    }\n}\nexports.default = GitSideBand;\n","module.exports = require(\"buffer\");","\"use strict\";\nvar __importDefault = (this && this.__importDefault) || function (mod) {\n    return (mod && mod.__esModule) ? mod : { \"default\": mod };\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nconst pako_1 = __importDefault(require(\"pako\"));\nconst path_1 = __importDefault(require(\"path\"));\nconst log_1 = __importDefault(require(\"./log\"));\nconst GitTree_1 = __importDefault(require(\"./GitTree\"));\nconst sha_js_1 = __importDefault(require(\"sha.js\"));\nconst GitCommit_1 = __importDefault(require(\"./GitCommit\"));\nconst readable_stream_1 = require(\"readable-stream\");\nconst GitObjectManager_1 = __importDefault(require(\"./GitObjectManager\"));\nconst types = {\n    commit: 0b0010000,\n    tree: 0b0100000,\n    blob: 0b0110000,\n    tag: 0b1000000,\n    ofs_delta: 0b1100000,\n    ref_delta: 0b1110000,\n};\n/**\n * Create a packfile stream\n *\n * @link https://isomorphic-git.github.io/docs/packObjects.html\n */\nasync function packObjects(fileSystem, dir, refs, depth, haves) {\n    const gitdir = path_1.default.join(dir, '.git');\n    let oids = new Set();\n    let shallows = new Set();\n    let unshallows = new Set();\n    let acks = [];\n    haves = haves ? haves : [];\n    const emitter = undefined;\n    const since = undefined;\n    for (const ref of refs) {\n        try {\n            let commits = await log_1.default(fileSystem, dir, gitdir, emitter, ref, depth, since);\n            let oldshallows = [];\n            for (let i = 0; i < commits.length; i++) {\n                let commit = commits[i];\n                if (haves.includes(commit.oid)) {\n                    acks.push({\n                        oid: ref,\n                    });\n                    break;\n                }\n                oids.add(commit.oid);\n                if (i === commits.length - 1) {\n                    if (!oldshallows.includes(commit.oid) && (depth !== undefined || since !== undefined)) {\n                        console.log('make it shallow', commit.oid);\n                        shallows.add(commit.oid);\n                    }\n                }\n                else if (oldshallows.includes(commit.oid)) {\n                    console.log('make it unshallow', commit.oid);\n                    unshallows.add(commit.oid);\n                }\n            }\n        }\n        catch (err) {\n            console.log(err);\n            // oh well.\n        }\n    }\n    let objects = await listObjects(fileSystem, dir, gitdir, Array.from(oids));\n    let packstream = new readable_stream_1.PassThrough();\n    pack(fileSystem, dir, undefined, [...objects], packstream);\n    return { packstream, shallows, unshallows, acks };\n}\nasync function listObjects(fileSystem, dir, gitdir = path_1.default.join(dir, '.git'), oids) {\n    let commits = new Set();\n    let trees = new Set();\n    let blobs = new Set();\n    // We don't do the purest simplest recursion, because we can\n    // avoid reading Blob objects entirely since the Tree objects\n    // tell us which oids are Blobs and which are Trees. And we\n    // do not need to recurse through commit parents.\n    async function walk(oid) {\n        let { type, object } = await GitObjectManager_1.default.read(fileSystem, gitdir, oid);\n        if (type === 'commit') {\n            commits.add(oid);\n            let commit = GitCommit_1.default.from(object);\n            let tree = commit.headers().tree;\n            await walk(tree);\n        }\n        else if (type === 'tree') {\n            trees.add(oid);\n            let tree = GitTree_1.default.from(object);\n            for (let entry of tree) {\n                if (entry.type === 'blob') {\n                    blobs.add(entry.oid);\n                }\n                // only recurse for trees\n                if (entry.type === 'tree') {\n                    await walk(entry.oid);\n                }\n            }\n        }\n    }\n    // Let's go walking!\n    for (let oid of oids) {\n        await walk(oid);\n    }\n    return [...commits, ...trees, ...blobs];\n}\nexports.listObjects = listObjects;\nasync function pack(fileSystem, dir, gitdir = path_1.default.join(dir, '.git'), oids, outputStream) {\n    let hash = sha_js_1.default('sha1');\n    function write(chunk, enc = undefined) {\n        if (enc) {\n            outputStream.write(chunk, enc);\n        }\n        else {\n            outputStream.write(chunk);\n        }\n        hash.update(chunk, enc);\n    }\n    function writeObject(object, stype) {\n        let lastFour;\n        let multibyte;\n        let length;\n        // Object type is encoded in bits 654\n        let type = types[stype];\n        if (type === undefined)\n            throw Error('Unrecognized type: ' + stype);\n        // The length encoding get complicated.\n        length = object.length;\n        // Whether the next byte is part of the variable-length encoded number\n        // is encoded in bit 7\n        multibyte = length > 0b1111 ? 0b10000000 : 0b0;\n        // Last four bits of length is encoded in bits 3210\n        lastFour = length & 0b1111;\n        // Discard those bits\n        length = length >>> 4;\n        // The first byte is then (1-bit multibyte?), (3-bit type), (4-bit least sig 4-bits of length)\n        let byte = (multibyte | type | lastFour).toString(16);\n        write(byte, 'hex');\n        // Now we keep chopping away at length 7-bits at a time until its zero,\n        // writing out the bytes in what amounts to little-endian order.\n        while (multibyte) {\n            multibyte = length > 0b01111111 ? 0b10000000 : 0b0;\n            byte = multibyte | (length & 0b01111111);\n            const unpaddedChunk = byte.toString(16);\n            const paddedChunk = '0'.repeat(2 - unpaddedChunk.length) + unpaddedChunk;\n            write(paddedChunk, 'hex');\n            length = length >>> 7;\n        }\n        // Lastly, we can compress and write the object.\n        write(Buffer.from(pako_1.default.deflate(object)));\n    }\n    write('PACK');\n    write('00000002', 'hex');\n    // Write a 4 byte (32-bit) int\n    const unpaddedChunk = oids.length.toString(16);\n    const paddedChunk = '0'.repeat(8 - unpaddedChunk.length) + unpaddedChunk;\n    write(paddedChunk, 'hex');\n    for (let oid of oids) {\n        let { type, object } = await GitObjectManager_1.default.read(fileSystem, gitdir, oid);\n        writeObject(object, type);\n    }\n    // Write SHA1 checksum\n    let digest = hash.digest();\n    outputStream.end(digest);\n    return outputStream;\n}\nexports.pack = pack;\nexports.default = packObjects;\n","\"use strict\";\nvar __importDefault = (this && this.__importDefault) || function (mod) {\n    return (mod && mod.__esModule) ? mod : { \"default\": mod };\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nconst path = require(\"path\");\nconst GitCommit_1 = __importDefault(require(\"./GitCommit\"));\nconst GitObjectManager_1 = __importDefault(require(\"./GitObjectManager\"));\nconst GitRefManager_1 = __importDefault(require(\"../upload-pack/GitRefManager\"));\nasync function logCommit(fileSystem, gitdir, oid, signing) {\n    try {\n        let { type, object } = await GitObjectManager_1.default.read(fileSystem, gitdir, oid);\n        if (type !== 'commit') {\n            throw new Error('expected type to be commit');\n        }\n        const commit = GitCommit_1.default.from(object);\n        const result = Object.assign({ oid }, commit.parse());\n        if (signing) {\n            result.payload = commit.withoutSignature();\n        }\n        return result;\n    }\n    catch (err) {\n        return {\n            oid,\n            error: err,\n        };\n    }\n}\nexports.logCommit = logCommit;\nfunction compareAge(a, b) {\n    return a.committer.timestamp - b.committer.timestamp;\n}\n/**\n * Get commit descriptions from the git history\n *\n * @link https://isomorphic-git.github.io/docs/log.html\n */\nasync function log(fileSystem, dir, gitdir = path.join(dir, '.git'), ref = 'HEAD', depth, since, // Date\nsigning = false) {\n    try {\n        let sinceTimestamp = since === undefined ? undefined : Math.floor(since.valueOf() / 1000);\n        // TODO: In the future, we may want to have an API where we return a\n        // async iterator that emits commits.\n        let commits = [];\n        let oid = await GitRefManager_1.default.resolve(fileSystem, gitdir, ref);\n        let tips = [await logCommit(fileSystem, gitdir, oid, signing)];\n        // eslint-disable-next-line\n        while (true) {\n            let commit = tips.pop();\n            // Stop the loop if we encounter an error\n            if (commit.error) {\n                commits.push(commit);\n                break;\n            }\n            // Stop the log if we've hit the age limit\n            if (sinceTimestamp !== undefined && commit.committer.timestamp <= sinceTimestamp) {\n                break;\n            }\n            commits.push(commit);\n            // Stop the loop if we have enough commits now.\n            if (depth !== undefined && commits.length === depth)\n                break;\n            // Add the parents of this commit to the queue\n            // Note: for the case of a commit with no parents, it will concat an empty array, having no net effect.\n            for (const oid of commit.parent) {\n                let commit = await logCommit(fileSystem, gitdir, oid, signing);\n                if (!tips.map((commit) => commit.oid).includes(commit.oid)) {\n                    tips.push(commit);\n                }\n            }\n            // Stop the loop if there are no more commit parents\n            if (tips.length === 0)\n                break;\n            // Process tips in order by age\n            tips.sort(compareAge);\n        }\n        return commits;\n    }\n    catch (err) {\n        err.caller = 'git.log';\n        throw err;\n    }\n}\nexports.default = log;\n","\"use strict\";\nvar __importDefault = (this && this.__importDefault) || function (mod) {\n    return (mod && mod.__esModule) ? mod : { \"default\": mod };\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nconst shasum_1 = __importDefault(require(\"./shasum\"));\nclass GitObject {\n    static hash({ type, object }) {\n        let buffer = Buffer.concat([Buffer.from(`${type} ${object.byteLength.toString()}\\0`), Buffer.from(object)]);\n        let oid = shasum_1.default(buffer);\n        return oid;\n    }\n    static wrap({ type, object }) {\n        let buffer = Buffer.concat([Buffer.from(`${type} ${object.byteLength.toString()}\\0`), object]);\n        let oid = shasum_1.default(buffer);\n        return {\n            oid,\n            buffer,\n        };\n    }\n    static unwrap({ oid, buffer }) {\n        if (oid) {\n            let sha = shasum_1.default(buffer);\n            if (sha !== oid) {\n                throw new Error(`SHA check failed! Expected ${oid}, computed ${sha}`);\n            }\n        }\n        let s = buffer.indexOf(32); // first space\n        let i = buffer.indexOf(0); // first null value\n        let type = buffer.slice(0, s).toString('utf8'); // get type of object\n        let length = buffer.slice(s + 1, i).toString('utf8'); // get type of object\n        let actualLength = buffer.length - (i + 1);\n        // verify length\n        if (parseInt(length) !== actualLength) {\n            throw new Error(`Length mismatch: expected ${length} bytes but got ${actualLength} instead.`);\n        }\n        return {\n            type,\n            object: Buffer.from(buffer.slice(i + 1)),\n        };\n    }\n}\nexports.default = GitObject;\n","\"use strict\";\nvar __importDefault = (this && this.__importDefault) || function (mod) {\n    return (mod && mod.__esModule) ? mod : { \"default\": mod };\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nconst sha1_1 = __importDefault(require(\"sha.js/sha1\"));\n// This is modeled after @dominictarr's \"shasum\" module,\n// but without the 'json-stable-stringify' dependency and\n// extra type-casting features.\nfunction shasum(buffer) {\n    return new sha1_1.default().update(buffer).digest('hex');\n}\nexports.default = shasum;\n","module.exports = require(\"sha.js/sha1\");","\"use strict\";\n/*::\ntype TreeEntry = {\n  mode: string,\n  path: string,\n  oid: string,\n  type?: string\n}\n*/\nObject.defineProperty(exports, \"__esModule\", { value: true });\nfunction parseBuffer(buffer) {\n    let _entries = [];\n    let cursor = 0;\n    while (cursor < buffer.length) {\n        let space = buffer.indexOf(32, cursor);\n        if (space === -1) {\n            throw new Error(`GitTree: Error parsing buffer at byte location ${cursor}: Could not find the next space character.`);\n        }\n        let nullchar = buffer.indexOf(0, cursor);\n        if (nullchar === -1) {\n            throw new Error(`GitTree: Error parsing buffer at byte location ${cursor}: Could not find the next null character.`);\n        }\n        let mode = buffer.slice(cursor, space).toString('utf8');\n        if (mode === '40000')\n            mode = '040000'; // makes it line up neater in printed output\n        let type = mode === '040000' ? 'tree' : 'blob';\n        let path = buffer.slice(space + 1, nullchar).toString('utf8');\n        let oid = buffer.slice(nullchar + 1, nullchar + 21).toString('hex');\n        cursor = nullchar + 21;\n        _entries.push({ mode, path, oid, type });\n    }\n    return _entries;\n}\nfunction limitModeToAllowed(mode) {\n    if (typeof mode === 'number') {\n        mode = mode.toString(8);\n    }\n    // tree\n    if (mode.match(/^0?4.*/))\n        return '40000'; // Directory\n    if (mode.match(/^1006.*/))\n        return '100644'; // Regular non-executable file\n    if (mode.match(/^1007.*/))\n        return '100755'; // Regular executable file\n    if (mode.match(/^120.*/))\n        return '120000'; // Symbolic link\n    if (mode.match(/^160.*/))\n        return '160000'; // Commit (git submodule reference)\n    throw new Error(`Could not understand file mode: ${mode}`);\n}\nfunction nudgeIntoShape(entry) {\n    if (!entry.oid && entry.sha) {\n        entry.oid = entry.sha; // Github\n    }\n    entry.mode = limitModeToAllowed(entry.mode); // index\n    if (!entry.type) {\n        entry.type = 'blob'; // index\n    }\n    return entry;\n}\nclass GitTree {\n    constructor(entries) {\n        if (Buffer.isBuffer(entries)) {\n            this._entries = parseBuffer(entries);\n        }\n        else if (Array.isArray(entries)) {\n            this._entries = entries.map(nudgeIntoShape);\n        }\n        else {\n            throw new Error('invalid type passed to GitTree constructor');\n        }\n    }\n    static from(tree) {\n        return new GitTree(tree);\n    }\n    render() {\n        return this._entries.map((entry) => `${entry.mode} ${entry.type} ${entry.oid}    ${entry.path}`).join('\\n');\n    }\n    toObject() {\n        return Buffer.concat(this._entries.map((entry) => {\n            let mode = Buffer.from(entry.mode.replace(/^0/, ''));\n            let space = Buffer.from(' ');\n            let path = Buffer.from(entry.path);\n            // let path = Buffer.from(entry.path, { encoding: 'utf8' })\n            let nullchar = Buffer.from([0]);\n            let oid = Buffer.from(entry.oid.match(/../g).map((n) => parseInt(n, 16)));\n            return Buffer.concat([mode, space, path, nullchar, oid]);\n        }));\n    }\n    entries() {\n        return this._entries;\n    }\n    *[Symbol.iterator]() {\n        for (let entry of this._entries) {\n            yield entry;\n        }\n    }\n}\nexports.default = GitTree;\n","module.exports = require(\"sha.js\");","module.exports = require(\"../../proto/js/Peer\");","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\n/**\n * Returns a 5 character long random string of lower case letters\n */\nfunction randomString() {\n    return Math.random()\n        .toString(36)\n        .replace(/[^a-z]+/g, '')\n        .substr(0, 5);\n}\nexports.randomString = randomString;\n/**\n * Inverts the provided promise\n * @param p Promise to invert\n */\nfunction invertPromise(p) {\n    return new Promise((res, rej) => p.then(rej, res));\n}\n/**\n * Gets the first promise fulfiled\n * @param ps List of promises\n */\nfunction firstPromiseFulfilled(ps) {\n    return invertPromise(Promise.all(ps.map(invertPromise)));\n}\nexports.firstPromiseFulfilled = firstPromiseFulfilled;\n","\"use strict\";\nvar __importDefault = (this && this.__importDefault) || function (mod) {\n    return (mod && mod.__esModule) ? mod : { \"default\": mod };\n};\nvar _a, _b;\nObject.defineProperty(exports, \"__esModule\", { value: true });\nconst dgram_1 = __importDefault(require(\"dgram\"));\nconst crypto_1 = __importDefault(require(\"crypto\"));\nconst PeerInfo_1 = __importDefault(require(\"./PeerInfo\"));\nconst events_1 = require(\"events\");\nconst Peer_js_1 = require(\"../../../proto/js/Peer.js\");\nconst { HandshakeMessage, PeerInfoMessage } = Peer_js_1.peer;\n// This module is based heavily on libp2p's mDNS module:\n// https://github.com/libp2p/js-libp2p-mdns\n// It is supposed to discover peers on the local network\n// This module was also generated with the help of:\n// https://nrempel.com/using-udp-multicast-with-node-js/\n//\n// \"\"\"\n// In computer networking, the multicast DNS (mDNS) protocol\n// resolves hostnames to IP addresses within small networks\n// that do not include a local name server\n// \"\"\"\nconst UDP_MULTICAST_PORT = parseInt((_a = process.env.UDP_MULTICAST_PORT) !== null && _a !== void 0 ? _a : '5353');\nconst UDP_MULTICAST_ADDR = (_b = process.env.UDP_MULTICAST_ADDR) !== null && _b !== void 0 ? _b : '224.0.0.251';\nclass MulticastBroadcaster extends events_1.EventEmitter {\n    constructor(addPeer, localPeerInfo, keyManager) {\n        super();\n        this.peerPubKeyMessages = new Map();\n        this.addPeer = addPeer;\n        this.localPeerInfo = localPeerInfo;\n        this.keyManager = keyManager;\n        this.interval = 1e3;\n        this.queryInterval = null;\n        // Create socket\n        this.socket = dgram_1.default.createSocket({ type: 'udp4', reuseAddr: true });\n        this.socket.bind(UDP_MULTICAST_PORT);\n        // Set up listener\n        this.socket.on('listening', (() => {\n            this.socket.addMembership(UDP_MULTICAST_ADDR);\n            const address = this.socket.address();\n        }).bind(this));\n        // Handle messages\n        this.socket.on('message', this.handleHandshakeMessages.bind(this));\n        // Start the query process\n        this.queryInterval = this.queryLAN();\n    }\n    /**\n     * Request a peer contact for the multicast peer discovery to check for\n     * @param publicKey Public key of the desired peer\n     */\n    async requestPeerContact(publicKey) {\n        const pubKeyBuf = Buffer.from(publicKey);\n        const randomMessage = crypto_1.default.randomBytes(16);\n        // Encrypt message\n        const encryptedPeerPubKey = await this.keyManager.encryptData(pubKeyBuf, pubKeyBuf);\n        const encryptedRandomMessage = await this.keyManager.encryptData(randomMessage, pubKeyBuf);\n        const encryptedLocalPubKey = await this.keyManager.encryptData(Buffer.from(this.keyManager.getPublicKey()), pubKeyBuf);\n        // Add to peer messages to be sent over multicast\n        this.peerPubKeyMessages.set(publicKey, {\n            encryptedLocalPubKey: Buffer.from(encryptedLocalPubKey),\n            encryptedPeerPubKey: Buffer.from(encryptedPeerPubKey),\n            rawRandomMessage: randomMessage,\n            encryptedRandomMessage: Buffer.from(encryptedRandomMessage),\n        });\n    }\n    // ==== Helper methods ==== //\n    queryLAN() {\n        const query = () => {\n            for (const pubKey of this.peerPubKeyMessages.keys()) {\n                const peerMessage = this.peerPubKeyMessages.get(pubKey);\n                if (peerMessage) {\n                    const handshakeMessage = HandshakeMessage.encode({\n                        targetPubKey: peerMessage.encryptedPeerPubKey,\n                        requestingPubKey: peerMessage.encryptedLocalPubKey,\n                        message: peerMessage.encryptedRandomMessage,\n                    }).finish();\n                    this.socket.send(handshakeMessage, 0, handshakeMessage.length, UDP_MULTICAST_PORT, UDP_MULTICAST_ADDR);\n                }\n            }\n        };\n        // Immediately start a query, then do it every interval.\n        query();\n        return setInterval(query, this.interval);\n    }\n    async handleHandshakeMessages(request, rinfo) {\n        var _a, _b;\n        try {\n            const { message, requestingPubKey, responsePeerInfo, targetPubKey } = HandshakeMessage.decode(request);\n            // Try to decrypt message and pubKey\n            const decryptedMessage = await this.keyManager.decryptData(Buffer.from(message));\n            const decryptedTargetPubKey = await this.keyManager.decryptData(Buffer.from(targetPubKey));\n            const decryptedRequestingPubKey = await this.keyManager.decryptData(Buffer.from(requestingPubKey));\n            const myPubKey = this.keyManager.getPublicKey();\n            if (decryptedRequestingPubKey.toString() == myPubKey) {\n                // Response\n                // Make sure decrypted bytes equal raw bytes in memory\n                const originalMessage = (_a = this.peerPubKeyMessages.get(decryptedTargetPubKey.toString())) === null || _a === void 0 ? void 0 : _a.rawRandomMessage;\n                if (decryptedMessage.toString() == (originalMessage === null || originalMessage === void 0 ? void 0 : originalMessage.toString())) {\n                    // Validated!\n                    // Add peer info to peerStore\n                    const { addresses, connectedAddr, pubKey } = PeerInfoMessage.decode(responsePeerInfo);\n                    const newPeerInfo = new PeerInfo_1.default(pubKey, addresses, connectedAddr);\n                    if (newPeerInfo) {\n                        this.addPeer(newPeerInfo);\n                        // Remove peerId from requested messages\n                        const pubKey = newPeerInfo.publicKey;\n                        this.peerPubKeyMessages.delete(pubKey);\n                        console.log(`New peer added to the store`);\n                        this.emit('found', newPeerInfo);\n                    }\n                    else {\n                        this.emit('error', 'I got a validated response. But no peerInfo');\n                    }\n                }\n            }\n            else {\n                // Requests on target node\n                // Try decrypting message\n                // Re-encrypt the data and send it on its way\n                const encryptedTargetPubKey = await this.keyManager.encryptData(Buffer.from(myPubKey), decryptedRequestingPubKey);\n                const encryptedMessage = await this.keyManager.encryptData(decryptedMessage, decryptedRequestingPubKey);\n                const encryptedPubKey = await this.keyManager.encryptData(decryptedRequestingPubKey, decryptedRequestingPubKey);\n                const encodedLocalPeerInfo = PeerInfoMessage.encode({\n                    addresses: this.localPeerInfo.AdressStringList,\n                    connectedAddr: (_b = this.localPeerInfo.connectedAddr) === null || _b === void 0 ? void 0 : _b.toString(),\n                    pubKey: this.localPeerInfo.publicKey,\n                }).finish();\n                const handshakeMessage = HandshakeMessage.encode({\n                    targetPubKey: Buffer.from(encryptedTargetPubKey),\n                    requestingPubKey: Buffer.from(encryptedPubKey),\n                    message: Buffer.from(encryptedMessage),\n                    responsePeerInfo: encodedLocalPeerInfo,\n                }).finish();\n                this.socket.send(handshakeMessage, 0, handshakeMessage.length, UDP_MULTICAST_PORT, UDP_MULTICAST_ADDR);\n            }\n        }\n        catch (err) {\n            // Couldn't decode message\n            // We don't want the multicast discovery to error on every message it coudln't decode!\n        }\n    }\n}\nexports.default = MulticastBroadcaster;\n","module.exports = require(\"dgram\");","module.exports = require(\"events\");","module.exports = require(\"../../proto/js/Peer.js\");","\"use strict\";\nvar __importDefault = (this && this.__importDefault) || function (mod) {\n    return (mod && mod.__esModule) ? mod : { \"default\": mod };\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nconst os_1 = __importDefault(require(\"os\"));\nconst path_1 = __importDefault(require(\"path\"));\nconst isomorphic_git_1 = __importDefault(require(\"isomorphic-git\"));\nconst Vault_1 = __importDefault(require(\"../vaults/Vault\"));\nconst encryptedfs_1 = require(\"encryptedfs\");\nclass VaultManager {\n    constructor(polykeyPath = `${os_1.default.homedir()}/.polykey`, fileSystem, keyManager) {\n        this.polykeyPath = polykeyPath;\n        this.fileSystem = fileSystem;\n        this.keyManager = keyManager;\n        this.metadataPath = path_1.default.join(polykeyPath, '.vaultKeys');\n        // Make polykeyPath if it doesn't exist\n        this.fileSystem.mkdirSync(this.polykeyPath, { recursive: true });\n        // Initialize stateful variables\n        this.vaults = new Map();\n        this.vaultKeys = new Map();\n        // Read in vault keys\n        this.loadMetadata();\n    }\n    /**\n     * Get a vault from the vault manager\n     * @param vaultName Name of desired vault\n     */\n    getVault(vaultName) {\n        if (this.vaults.has(vaultName)) {\n            const vault = this.vaults.get(vaultName);\n            return vault;\n        }\n        else if (this.vaultKeys.has(vaultName)) {\n            // vault not in map, create new instance\n            this.validateVault(vaultName);\n            const vaultKey = this.vaultKeys.get(vaultName);\n            const vault = new Vault_1.default(vaultName, vaultKey, this.polykeyPath);\n            this.vaults.set(vaultName, vault);\n            return vault;\n        }\n        else {\n            throw Error(`vault does not exist in memory: '${vaultName}'`);\n        }\n    }\n    /**\n     * Get a vault from the vault manager\n     * @param vaultName Unique name of new vault\n     * @param key Optional key to use for the vault encryption, otherwise it is generated\n     */\n    async createVault(vaultName, key) {\n        if (this.vaultExists(vaultName)) {\n            throw Error('Vault already exists!');\n        }\n        try {\n            const path = path_1.default.join(this.polykeyPath, vaultName);\n            // Directory not present, create one\n            this.fileSystem.mkdirSync(path, { recursive: true });\n            // Create key if not provided\n            let vaultKey;\n            if (!key) {\n                // Generate new key\n                vaultKey = await this.keyManager.generateKey(`${vaultName}-Key`, this.keyManager.getPrivateKey(), false);\n            }\n            else {\n                // Assign key if it is provided\n                vaultKey = key;\n            }\n            this.vaultKeys.set(vaultName, vaultKey);\n            this.writeMetadata();\n            // Create vault\n            const vault = new Vault_1.default(vaultName, vaultKey, this.polykeyPath);\n            // Init repository for vault\n            const vaultPath = path_1.default.join(this.polykeyPath, vaultName);\n            const efs = vault.EncryptedFS;\n            const fileSystem = { promises: efs.promises };\n            await isomorphic_git_1.default.init({\n                fs: fileSystem,\n                dir: vaultPath,\n            });\n            // Initial commit\n            await isomorphic_git_1.default.commit({\n                fs: fileSystem,\n                dir: vaultPath,\n                author: {\n                    name: vaultName,\n                },\n                message: 'init commit',\n            });\n            // Write packed-refs file because isomorphic git goes searching for it\n            // and apparently its not autogenerated\n            efs.writeFileSync(path_1.default.join(vaultPath, '.git', 'packed-refs'), '# pack-refs with: peeled fully-peeled sorted');\n            // Set vault\n            this.vaults.set(vaultName, vault);\n            return this.getVault(vaultName);\n        }\n        catch (err) {\n            // Delete vault dir and garbage collect\n            this.destroyVault(vaultName);\n            throw err;\n        }\n    }\n    /**\n     * Get a vault from the vault manager\n     * @param vaultName Name of vault to be cloned\n     * @param address Address of polykey node that owns vault to be cloned\n     * @param getSocket Function to get an active connection to provided address\n     */\n    async cloneVault(vaultName, gitRequest) {\n        // Confirm it doesn't exist locally already\n        if (this.vaultExists(vaultName)) {\n            throw Error('Vault name already exists locally, try pulling instead');\n        }\n        const vaultUrl = `http://0.0.0.0/${vaultName}`;\n        // First check if it exists on remote\n        const info = await isomorphic_git_1.default.getRemoteInfo({\n            http: gitRequest,\n            url: vaultUrl,\n        });\n        if (!info.refs) {\n            throw Error(`Peer does not have vault: '${vaultName}'`);\n        }\n        // Create new efs first\n        // Generate new key\n        const vaultKey = await this.keyManager.generateKey(`${vaultName}-Key`, this.keyManager.getPrivateKey());\n        // Set filesystem\n        const vfsInstance = new (require('virtualfs').VirtualFS)();\n        const newEfs = new encryptedfs_1.EncryptedFS(vaultKey, vfsInstance, vfsInstance, this.fileSystem, process);\n        // Clone vault from address\n        await isomorphic_git_1.default.clone({\n            fs: { promises: newEfs.promises },\n            http: gitRequest,\n            dir: path_1.default.join(this.polykeyPath, vaultName),\n            url: vaultUrl,\n            ref: 'master',\n            singleBranch: true,\n        });\n        // Finally return the vault\n        const vault = new Vault_1.default(vaultName, vaultKey, this.polykeyPath);\n        this.vaults.set(vaultName, vault);\n        return vault;\n    }\n    /**\n     * Determines whether the vault exists\n     * @param vaultName Name of desired vault\n     */\n    vaultExists(vaultName) {\n        const path = path_1.default.join(this.polykeyPath, vaultName);\n        const vaultExists = this.fileSystem.existsSync(path);\n        return vaultExists;\n    }\n    /**\n     * [WARNING] Destroys a certain vault and all its secrets\n     * @param vaultName Name of vault to be destroyed\n     */\n    destroyVault(vaultName) {\n        // this is convenience function for removing all tags\n        // and triggering garbage collection\n        // destruction is a better word as we should ensure all traces is removed\n        const path = path_1.default.join(this.polykeyPath, vaultName);\n        // Remove directory on file system\n        if (this.fileSystem.existsSync(path)) {\n            this.fileSystem.rmdirSync(path, { recursive: true });\n        }\n        // Remove from maps\n        this.vaults.delete(vaultName);\n        this.vaultKeys.delete(vaultName);\n        // Write to metadata file\n        this.writeMetadata();\n        const vaultPathExists = this.fileSystem.existsSync(path);\n        if (vaultPathExists) {\n            throw Error('Vault folder could not be destroyed!');\n        }\n    }\n    /**\n     * List the names of all vaults in memory\n     */\n    listVaults() {\n        return Array.from(this.vaults.keys());\n    }\n    /* ============ HELPERS =============== */\n    validateVault(vaultName) {\n        if (!this.vaults.has(vaultName)) {\n            throw Error(`vault does not exist in memory: '${vaultName}'`);\n        }\n        if (!this.vaultKeys.has(vaultName)) {\n            throw Error(`vault key does not exist in memory: '${vaultName}'`);\n        }\n        const vaultPath = path_1.default.join(this.polykeyPath, vaultName);\n        if (!this.fileSystem.existsSync(vaultPath)) {\n            throw Error(`vault directory does not exist: '${vaultPath}'`);\n        }\n    }\n    async writeMetadata() {\n        const metadata = JSON.stringify([...this.vaultKeys]);\n        const encryptedMetadata = await this.keyManager.encryptData(Buffer.from(metadata));\n        await this.fileSystem.promises.writeFile(this.metadataPath, encryptedMetadata);\n    }\n    async loadMetadata() {\n        // Check if file exists\n        if (this.fileSystem.existsSync(this.metadataPath) && this.keyManager.identityLoaded) {\n            const encryptedMetadata = this.fileSystem.readFileSync(this.metadataPath);\n            const metadata = (await this.keyManager.decryptData(encryptedMetadata)).toString();\n            for (const [key, value] of new Map(JSON.parse(metadata))) {\n                this.vaultKeys.set(key, Buffer.from(value));\n            }\n            // Initialize vaults in memory\n            for (const [vaultName, vaultKey] of this.vaultKeys.entries()) {\n                const path = path_1.default.join(this.polykeyPath, vaultName);\n                if (this.fileSystem.existsSync(path)) {\n                    const vault = new Vault_1.default(vaultName, vaultKey, this.polykeyPath);\n                    this.vaults.set(vaultName, vault);\n                }\n            }\n        }\n    }\n}\nexports.default = VaultManager;\n","\"use strict\";\nvar __importDefault = (this && this.__importDefault) || function (mod) {\n    return (mod && mod.__esModule) ? mod : { \"default\": mod };\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nconst fs_1 = __importDefault(require(\"fs\"));\nconst path_1 = __importDefault(require(\"path\"));\nconst isomorphic_git_1 = __importDefault(require(\"isomorphic-git\"));\nconst encryptedfs_1 = require(\"encryptedfs\");\nconst async_mutex_1 = require(\"async-mutex\");\nclass Vault {\n    constructor(name, symKey, baseDir) {\n        // Concurrency\n        this.mutex = new async_mutex_1.Mutex();\n        // how do we create pub/priv key pair?\n        // do we use the same gpg pub/priv keypair\n        this.key = symKey;\n        // Set filesystem\n        const vfsInstance = new (require('virtualfs').VirtualFS)();\n        this.efs = new encryptedfs_1.EncryptedFS(this.key, vfsInstance, vfsInstance, fs_1.default, process);\n        this.name = name;\n        this.vaultPath = path_1.default.join(baseDir, name);\n        // make the vault directory\n        this.efs.mkdirSync(this.vaultPath, { recursive: true });\n        this.secrets = new Map();\n        this.loadSecrets();\n        // Load metadata\n        this.metadataPath = path_1.default.join(this.vaultPath, '.vault', 'metadata');\n        this.loadMetadata();\n    }\n    /**\n     * Returns the Encrypted File System used for vault operations\n     */\n    get EncryptedFS() {\n        return this.efs;\n    }\n    /**\n     * Determines whether a secret exists in the vault\n     * @param secretName Name of desired secret\n     */\n    secretExists(secretName) {\n        const secretPath = path_1.default.join(this.vaultPath, secretName);\n        return this.secrets.has(secretName) && this.efs.existsSync(secretPath);\n    }\n    /**\n     * Adds a secret to the vault\n     * @param secretName Name of new secret\n     * @param secret Content of new secret\n     */\n    async addSecret(secretName, secret) {\n        const release = await this.mutex.acquire();\n        try {\n            // Check if secret already exists\n            if (this.secrets.has(secretName)) {\n                throw Error('Secret already exists, try updating it instead.');\n            }\n            const writePath = path_1.default.join(this.vaultPath, secretName);\n            // Write secret\n            await this.efs.promises.writeFile(writePath, secret, {});\n            // Update secrets map\n            this.secrets.set(secretName, secret);\n            // Auto commit message\n            await this.commitChanges(`Add secret: ${secretName}`, secretName, 'added');\n        }\n        catch (error) {\n            release();\n            throw error;\n        }\n        finally {\n            release();\n        }\n    }\n    /**\n     * Updates a secret in the vault\n     * @param secretName Name of secret to be updated\n     * @param secret Content of updated secret\n     */\n    async updateSecret(secretName, secret) {\n        const release = await this.mutex.acquire();\n        try {\n            // Check if secret already exists\n            if (!this.secrets.has(secretName)) {\n                throw Error('Secret does not exist, try adding it instead.');\n            }\n            const writePath = path_1.default.join(this.vaultPath, secretName);\n            // Write secret\n            await this.efs.promises.writeFile(writePath, secret, {});\n            // Update secrets map\n            this.secrets.set(secretName, secret);\n            // Auto commit message\n            await this.commitChanges(`Update secret: ${secretName}`, secretName, 'modified');\n        }\n        catch (error) {\n            release();\n            throw error;\n        }\n        finally {\n            release();\n        }\n    }\n    /**\n     * Get a secret from the vault\n     * @param secretName Name of secret to be retrieved\n     */\n    getSecret(secretName) {\n        if (this.secrets.has(secretName)) {\n            const secret = this.secrets.get(secretName);\n            if (secret) {\n                return secret;\n            }\n            else {\n                const secretPath = path_1.default.join(this.vaultPath, secretName);\n                // TODO: this should be async\n                const secretBuf = this.efs.readFileSync(secretPath, {});\n                this.secrets.set(secretName, secretBuf);\n                return secretBuf;\n            }\n        }\n        throw Error('Secret: ' + secretName + ' does not exist');\n    }\n    /**\n     * [WARNING] Removes a secret from the vault\n     * @param secretName Name of secret to be removed\n     */\n    async removeSecret(secretName) {\n        const release = await this.mutex.acquire();\n        try {\n            if (this.secrets.has(secretName)) {\n                const successful = this.secrets.delete(secretName);\n                // Remove from fs\n                await this.efs.promises.unlink(path_1.default.join(this.vaultPath, secretName));\n                // Auto commit message\n                await this.commitChanges(`Remove secret: ${secretName}`, secretName, 'removed');\n                if (successful) {\n                    return;\n                }\n                throw Error('Secret: ' + secretName + ' was not removed');\n            }\n            throw Error('Secret: ' + secretName + ' does not exist');\n        }\n        catch (error) {\n            release();\n            throw error;\n        }\n        finally {\n            release();\n        }\n    }\n    /**\n     * Lists all the secrets currently in the vault\n     */\n    listSecrets() {\n        let secrets = Array.from(this.secrets.keys());\n        return secrets;\n    }\n    tagVault() { }\n    untagVault() { }\n    /////////////\n    // Sharing //\n    /////////////\n    /**\n     * Allows a particular public key to access the vault\n     * @param publicKey Public key to share with\n     */\n    shareVault(publicKey) {\n        if (this.sharedPubKeys.has(name)) {\n            throw Error('Vault is already shared with given public key');\n        }\n        this.sharedPubKeys.add(publicKey);\n        // Write metadata\n        this.writeMetadata();\n    }\n    /**\n     * Removes access to the vault for a particular public key\n     * @param publicKey Public key to unshare with\n     */\n    unshareVault(publicKey) {\n        if (!this.sharedPubKeys.has(publicKey)) {\n            throw Error('Vault is not shared with given public key');\n        }\n        this.sharedPubKeys.delete(publicKey);\n        // Write metadata\n        this.writeMetadata();\n    }\n    /**\n     * Determines if a particular public key can access the vault\n     * @param publicKey Public key to check\n     */\n    peerCanAccess(publicKey) {\n        // return this.sharedPubKeys.has(publicKey)\n        return true;\n    }\n    /**\n     * Pulls the vault from a specific address\n     * @param address Address of polykey node that owns vault to be pulled\n     * @param getSocket Function to get an active connection to provided address\n     */\n    async pullVault(gitClient) {\n        const release = await this.mutex.acquire();\n        try {\n            // Strangely enough this is needed for pulls along with ref set to 'HEAD'\n            // In isogit's documentation, this is just to get the currentBranch name\n            // But it solves a bug whereby if not used, git.pull complains that it can't\n            // find the master branch or HEAD\n            await isomorphic_git_1.default.currentBranch({\n                fs: { promises: this.efs.promises },\n                dir: this.vaultPath,\n                fullname: true,\n            });\n            // First pull\n            await isomorphic_git_1.default.pull({\n                fs: { promises: this.efs.promises },\n                http: gitClient,\n                dir: this.vaultPath,\n                url: 'http://' + '0.0.0.0:0' + '/' + this.name,\n                ref: 'HEAD',\n                singleBranch: true,\n                author: {\n                    name: this.name,\n                },\n            });\n            // Load any new secrets\n            this.loadSecrets();\n        }\n        catch (error) {\n            release();\n            throw error;\n        }\n        finally {\n            release();\n        }\n    }\n    async getVaultHistory(depth) {\n        const logs = await isomorphic_git_1.default.log({\n            fs: { promises: this.efs.promises },\n            dir: this.vaultPath,\n            depth,\n        });\n        return logs.map((commit) => {\n            return commit.commit.message;\n        });\n    }\n    // ============== Helper methods ============== //\n    writeMetadata() {\n        // mkdir first\n        this.efs.mkdirSync(path_1.default.dirname(this.metadataPath), { recursive: true });\n        // Create and write metadata\n        const metadata = {\n            sharedPubKeys: Array.from(this.sharedPubKeys.keys()),\n        };\n        this.efs.writeFileSync(this.metadataPath, JSON.stringify(metadata));\n    }\n    loadMetadata() {\n        if (this.efs.existsSync(this.metadataPath)) {\n            const fileContents = this.efs.readFileSync(this.metadataPath).toString();\n            const metadata = JSON.parse(fileContents);\n            this.sharedPubKeys = new Set(metadata.sharedPubKeys);\n        }\n        else {\n            // Need to create it\n            this.sharedPubKeys = new Set();\n            this.writeMetadata();\n        }\n    }\n    async commitChanges(message, secretName, action) {\n        if (action == 'removed') {\n            await isomorphic_git_1.default.remove({\n                fs: { promises: this.efs.promises },\n                dir: this.vaultPath,\n                filepath: secretName,\n            });\n        }\n        else {\n            await isomorphic_git_1.default.add({\n                fs: { promises: this.efs.promises },\n                dir: this.vaultPath,\n                filepath: secretName,\n            });\n        }\n        return await isomorphic_git_1.default.commit({\n            fs: { promises: this.efs.promises },\n            dir: this.vaultPath,\n            author: {\n                name: this.name,\n            },\n            message: message,\n        });\n    }\n    loadSecrets() {\n        const secrets = fs_1.default.readdirSync(this.vaultPath, undefined);\n        // Remove all secrets first\n        this.secrets.clear();\n        // Load secrets\n        for (const secret of secrets.filter((s) => s[0] != '.')) {\n            this.secrets.set(secret, null);\n        }\n    }\n}\nexports.default = Vault;\n","module.exports = require(\"async-mutex\");","\"use strict\";\nvar __importDefault = (this && this.__importDefault) || function (mod) {\n    return (mod && mod.__esModule) ? mod : { \"default\": mod };\n};\nvar __importStar = (this && this.__importStar) || function (mod) {\n    if (mod && mod.__esModule) return mod;\n    var result = {};\n    if (mod != null) for (var k in mod) if (Object.hasOwnProperty.call(mod, k)) result[k] = mod[k];\n    result[\"default\"] = mod;\n    return result;\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nconst os_1 = __importDefault(require(\"os\"));\nconst fs_1 = __importDefault(require(\"fs\"));\nconst net_1 = __importDefault(require(\"net\"));\nconst path_1 = __importDefault(require(\"path\"));\nconst process_1 = __importDefault(require(\"process\"));\nconst child_process_1 = require(\"child_process\");\nconst Polykey_1 = __importStar(require(\"../Polykey\"));\nconst configstore_1 = __importDefault(require(\"configstore\"));\nconst PolykeyClient_1 = __importDefault(require(\"./PolykeyClient\"));\nconst Agent_1 = require(\"../../../proto/js/Agent\");\nconst { AgentMessage, AgentMessageType, CreateSecretRequestMessage, CreateSecretResponseMessage, DecryptFileRequestMessage, DecryptFileResponseMessage, DeleteKeyRequestMessage, DeleteKeyResponseMessage, DeriveKeyRequestMessage, DeriveKeyResponseMessage, DestroySecretRequestMessage, DestroySecretResponseMessage, DestroyVaultRequestMessage, DestroyVaultResponseMessage, EncryptFileRequestMessage, EncryptFileResponseMessage, ErrorMessage, GetPrimaryKeyPairRequestMessage, GetPrimaryKeyPairResponseMessage, GetSecretRequestMessage, GetSecretResponseMessage, GetKeyRequestMessage, GetKeyResponseMessage, ListKeysRequestMessage, ListKeysResponseMessage, ListNodesRequestMessage, ListNodesResponseMessage, ListSecretsRequestMessage, ListSecretsResponseMessage, ListVaultsRequestMessage, ListVaultsResponseMessage, NewNodeRequestMessage, NewNodeResponseMessage, NewVaultRequestMessage, NewVaultResponseMessage, RegisterNodeRequestMessage, RegisterNodeResponseMessage, SignFileRequestMessage, SignFileResponseMessage, UpdateSecretRequestMessage, UpdateSecretResponseMessage, VerifyFileRequestMessage, VerifyFileResponseMessage, } = Agent_1.agent;\nclass PolykeyAgent {\n    constructor() {\n        this.persistentStore = new configstore_1.default('polykey');\n        // For storing the state of each polykey node\n        // Keys are the paths to the polykey node, e.g. '~/.polykey'\n        this.polykeyMap = new Map();\n        this.socketPath = PolykeyAgent.SocketPath;\n        // Make sure the socket file doesn't already exist (agent is already running)\n        if (fs_1.default.existsSync(this.socketPath)) {\n            fs_1.default.unlinkSync(this.socketPath);\n        }\n        // Make the socket path if it doesn't exist\n        if (!fs_1.default.existsSync(path_1.default.dirname(this.socketPath))) {\n            fs_1.default.promises.mkdir(path_1.default.dirname(this.socketPath));\n        }\n        // Load polykeys\n        const nodePaths = this.persistentStore.get('nodePaths');\n        if (nodePaths === null || nodePaths === void 0 ? void 0 : nodePaths.values) {\n            for (const path of nodePaths) {\n                if (fs_1.default.existsSync(path)) {\n                    this.setPolyKey(path, new Polykey_1.default(path, fs_1.default));\n                }\n                else {\n                    this.removeNodePath(path);\n                }\n            }\n        }\n        else {\n            this.persistentStore.set('nodePaths', []);\n        }\n        // Start the server\n        this.server = net_1.default.createServer().listen(this.socketPath);\n        this.server.on('connection', (socket) => {\n            this.handleClientCommunication(socket);\n        });\n    }\n    setPolyKey(nodePath, pk) {\n        this.polykeyMap.set(nodePath, pk);\n        const nodePathSet = new Set(this.persistentStore.get('nodePaths'));\n        nodePathSet.add(nodePath);\n        this.persistentStore.set('nodePaths', Array.from(nodePathSet.values()));\n    }\n    removeNodePath(nodePath) {\n        this.polykeyMap.delete(nodePath);\n        const nodePathSet = new Set(this.persistentStore.get('nodePaths'));\n        nodePathSet.delete(nodePath);\n        this.persistentStore.set('nodePaths', Array.from(nodePathSet.values()));\n    }\n    getPolyKey(nodePath, failOnLocked = true) {\n        const pk = this.polykeyMap.get(nodePath);\n        if (this.polykeyMap.has(nodePath) && pk) {\n            if (fs_1.default.existsSync(nodePath)) {\n                if (failOnLocked && !pk.keyManager.identityLoaded) {\n                    throw Error(`node path exists in memory but is locked: ${nodePath}`);\n                }\n                else {\n                    return pk;\n                }\n            }\n            else {\n                this.removeNodePath(nodePath);\n                throw Error(`node path exists in memory but does not exist on file system: ${nodePath}`);\n            }\n        }\n        else {\n            this.removeNodePath(nodePath);\n            throw Error(`node path does not exist in memory: ${nodePath}`);\n        }\n    }\n    get AllNodePaths() {\n        return Array.from(this.polykeyMap.keys()).filter((nodePath) => {\n            try {\n                this.getPolyKey(nodePath, false);\n                return true;\n            }\n            catch (_a) {\n                return false;\n            }\n        });\n    }\n    get UnlockedNodePaths() {\n        return this.AllNodePaths.filter((nodePath) => {\n            try {\n                return this.getPolyKey(nodePath, false).keyManager.identityLoaded;\n            }\n            catch (_a) {\n                return false;\n            }\n        });\n    }\n    stop() {\n        this.polykeyMap.forEach((pk) => {\n            pk.peerManager.multicastBroadcaster.socket.close();\n            pk.peerManager.server.forceShutdown();\n        });\n        this.server.close();\n    }\n    handleClientCommunication(socket) {\n        socket.on('data', async (encodedMessage) => {\n            var _a;\n            try {\n                const { type, nodePath, subMessage } = AgentMessage.decode(encodedMessage);\n                let response = undefined;\n                switch (type) {\n                    case AgentMessageType.STATUS:\n                        response = Buffer.from('online');\n                        break;\n                    case AgentMessageType.STOP_AGENT:\n                        this.stop();\n                        process_1.default.exit();\n                    // eslint-disable-next-line\n                    case AgentMessageType.REGISTER_NODE:\n                        response = await this.registerNode(nodePath, subMessage);\n                        break;\n                    case AgentMessageType.NEW_NODE:\n                        response = await this.newNode(nodePath, subMessage);\n                        break;\n                    case AgentMessageType.LIST_NODES:\n                        response = this.listNodes(subMessage);\n                        break;\n                    case AgentMessageType.DERIVE_KEY:\n                        response = await this.deriveKey(nodePath, subMessage);\n                        break;\n                    case AgentMessageType.LIST_KEYS:\n                        response = await this.listKeys(nodePath);\n                        break;\n                    case AgentMessageType.GET_KEY:\n                        response = await this.getKey(nodePath, subMessage);\n                        break;\n                    case AgentMessageType.GET_PRIMARY_KEYPAIR:\n                        response = await this.getPrimaryKeyPair(nodePath, subMessage);\n                        break;\n                    case AgentMessageType.DELETE_KEY:\n                        response = await this.deleteKey(nodePath, subMessage);\n                        break;\n                    case AgentMessageType.SIGN_FILE:\n                        response = await this.signFile(nodePath, subMessage);\n                        break;\n                    case AgentMessageType.VERIFY_FILE:\n                        response = await this.verifyFile(nodePath, subMessage);\n                        break;\n                    case AgentMessageType.ENCRYPT_FILE:\n                        response = await this.encryptFile(nodePath, subMessage);\n                        break;\n                    case AgentMessageType.DECRYPT_FILE:\n                        response = await this.decryptFile(nodePath, subMessage);\n                        break;\n                    case AgentMessageType.LIST_VAULTS:\n                        response = await this.listVaults(nodePath);\n                        break;\n                    case AgentMessageType.NEW_VAULT:\n                        response = await this.newVault(nodePath, subMessage);\n                        break;\n                    case AgentMessageType.DESTROY_VAULT:\n                        response = await this.destroyVault(nodePath, subMessage);\n                        break;\n                    case AgentMessageType.LIST_SECRETS:\n                        response = await this.listSecrets(nodePath, subMessage);\n                        break;\n                    case AgentMessageType.CREATE_SECRET:\n                        response = await this.createSecret(nodePath, subMessage);\n                        break;\n                    case AgentMessageType.DESTROY_SECRET:\n                        response = await this.destroySecret(nodePath, subMessage);\n                        break;\n                    case AgentMessageType.GET_SECRET:\n                        response = await this.getSecret(nodePath, subMessage);\n                        break;\n                    case AgentMessageType.UPDATE_SECRET:\n                        response = await this.updateSecret(nodePath, subMessage);\n                        break;\n                    default:\n                        throw Error(`message type not supported: ${AgentMessageType[type]}`);\n                }\n                if (response) {\n                    const encodedResponse = AgentMessage.encode({\n                        type: type,\n                        isResponse: true,\n                        nodePath: nodePath,\n                        subMessage: response,\n                    }).finish();\n                    socket.write(encodedResponse);\n                }\n                else {\n                    throw Error('something went wrong');\n                }\n            }\n            catch (err) {\n                const errorResponse = AgentMessage.encode({\n                    type: AgentMessageType.ERROR,\n                    isResponse: true,\n                    nodePath: undefined,\n                    subMessage: ErrorMessage.encode({ error: (_a = err.message) !== null && _a !== void 0 ? _a : err }).finish(),\n                }).finish();\n                socket.write(errorResponse);\n            }\n            // Close connection\n            socket.end();\n        });\n    }\n    // Register an existing polykey agent\n    async registerNode(nodePath, request) {\n        const { passphrase } = RegisterNodeRequestMessage.decode(request);\n        let pk;\n        if (this.polykeyMap.has(nodePath)) {\n            pk = this.getPolyKey(nodePath, false);\n            if (pk.keyManager.identityLoaded) {\n                throw Error(`node path is already loaded and unlocked: '${nodePath}'`);\n            }\n            await pk.keyManager.unlockIdentity(passphrase);\n        }\n        else {\n            const km = new Polykey_1.KeyManager(nodePath, fs_1.default);\n            await km.unlockIdentity(passphrase);\n            // Create polykey class\n            pk = new Polykey_1.default(nodePath, fs_1.default, km);\n        }\n        // Load all metadata\n        await pk.keyManager.loadMetadata();\n        pk.peerManager.loadMetadata();\n        await pk.vaultManager.loadMetadata();\n        // Set polykey class\n        this.setPolyKey(nodePath, pk);\n        // Encode and send response\n        const response = NewNodeResponseMessage.encode({\n            successful: pk.keyManager.identityLoaded && this.polykeyMap.has(nodePath),\n        }).finish();\n        return response;\n    }\n    // Create a new polykey agent\n    async newNode(nodePath, request) {\n        // Throw if path already exists\n        if (this.polykeyMap.has(nodePath) && fs_1.default.existsSync(nodePath)) {\n            throw Error(`node path '${nodePath}' is already loaded`);\n        }\n        else if (fs_1.default.existsSync(nodePath)) {\n            throw Error(`node path already exists: '${nodePath}'`);\n        }\n        const { name, email, passphrase, nbits } = NewNodeRequestMessage.decode(request);\n        const km = new Polykey_1.KeyManager(nodePath, fs_1.default);\n        await km.generateKeyPair(name, email, passphrase, nbits == 0 ? undefined : nbits, true, (info) => {\n            // socket.write(JSON.stringify(info))\n        });\n        // Create and set polykey class\n        const pk = new Polykey_1.default(nodePath, fs_1.default, km);\n        this.setPolyKey(nodePath, pk);\n        // Encode and send response\n        const response = NewNodeResponseMessage.encode({\n            successful: km.identityLoaded && this.polykeyMap.has(nodePath),\n        }).finish();\n        return response;\n    }\n    // Create a new polykey agent\n    listNodes(request) {\n        const { unlockedOnly } = ListNodesRequestMessage.decode(request);\n        if (unlockedOnly) {\n            return ListNodesResponseMessage.encode({ nodes: this.UnlockedNodePaths }).finish();\n        }\n        else {\n            return ListNodesResponseMessage.encode({ nodes: this.AllNodePaths }).finish();\n        }\n    }\n    /////////////////////////\n    // KeyManager commands //\n    /////////////////////////\n    async deriveKey(nodePath, request) {\n        const { keyName, passphrase } = DeriveKeyRequestMessage.decode(request);\n        const pk = this.getPolyKey(nodePath);\n        await pk.keyManager.generateKey(keyName, passphrase);\n        return DeriveKeyResponseMessage.encode({ successful: true }).finish();\n    }\n    async listKeys(nodePath) {\n        const pk = this.getPolyKey(nodePath);\n        const keyNames = pk.keyManager.listKeys();\n        return ListKeysResponseMessage.encode({ keyNames }).finish();\n    }\n    async getKey(nodePath, request) {\n        const { keyName } = GetKeyRequestMessage.decode(request);\n        const pk = this.getPolyKey(nodePath);\n        const keyContent = pk.keyManager.getKey(keyName).toString();\n        return GetKeyResponseMessage.encode({ keyContent }).finish();\n    }\n    async getPrimaryKeyPair(nodePath, request) {\n        const { includePrivateKey } = GetPrimaryKeyPairRequestMessage.decode(request);\n        const pk = this.getPolyKey(nodePath);\n        const keypair = pk.keyManager.getKeyPair();\n        return GetPrimaryKeyPairResponseMessage.encode({\n            publicKey: keypair.public,\n            privateKey: includePrivateKey ? keypair.private : undefined,\n        }).finish();\n    }\n    async deleteKey(nodePath, request) {\n        const { keyName } = DeleteKeyRequestMessage.decode(request);\n        const pk = this.getPolyKey(nodePath);\n        const successful = await pk.keyManager.deleteKey(keyName);\n        return DeleteKeyResponseMessage.encode({ successful }).finish();\n    }\n    /////////////////////\n    // Crypto commands //\n    /////////////////////\n    async signFile(nodePath, request) {\n        const { filePath, privateKeyPath, passphrase } = SignFileRequestMessage.decode(request);\n        const pk = this.getPolyKey(nodePath);\n        const signaturePath = await pk.keyManager.signFile(filePath, privateKeyPath, passphrase);\n        return SignFileResponseMessage.encode({ signaturePath }).finish();\n    }\n    async verifyFile(nodePath, request) {\n        const { filePath, publicKeyPath } = VerifyFileRequestMessage.decode(request);\n        const pk = this.getPolyKey(nodePath);\n        const verified = await pk.keyManager.verifyFile(filePath, publicKeyPath);\n        return VerifyFileResponseMessage.encode({ verified }).finish();\n    }\n    async encryptFile(nodePath, request) {\n        const { filePath, publicKeyPath } = EncryptFileRequestMessage.decode(request);\n        const pk = this.getPolyKey(nodePath);\n        const encryptedPath = await pk.keyManager.encryptFile(filePath, publicKeyPath);\n        return EncryptFileResponseMessage.encode({ encryptedPath }).finish();\n    }\n    async decryptFile(nodePath, request) {\n        const { filePath, privateKeyPath, passphrase } = DecryptFileRequestMessage.decode(request);\n        const pk = this.getPolyKey(nodePath);\n        const decryptedPath = await pk.keyManager.decryptFile(filePath, privateKeyPath, passphrase);\n        return DecryptFileResponseMessage.encode({ decryptedPath }).finish();\n    }\n    //////////////////////\n    // Vault Operations //\n    //////////////////////\n    async listVaults(nodePath) {\n        const pk = this.getPolyKey(nodePath);\n        const vaultNames = pk.vaultManager.listVaults();\n        return ListVaultsResponseMessage.encode({ vaultNames }).finish();\n    }\n    async newVault(nodePath, request) {\n        const { vaultName } = NewVaultRequestMessage.decode(request);\n        const pk = this.getPolyKey(nodePath);\n        await pk.vaultManager.createVault(vaultName);\n        return NewVaultResponseMessage.encode({ successful: true }).finish();\n    }\n    async destroyVault(nodePath, request) {\n        const { vaultName } = DestroyVaultRequestMessage.decode(request);\n        const pk = this.getPolyKey(nodePath);\n        pk.vaultManager.destroyVault(vaultName);\n        return DestroyVaultResponseMessage.encode({ successful: true }).finish();\n    }\n    ///////////////////////\n    // Secret Operations //\n    ///////////////////////\n    async listSecrets(nodePath, request) {\n        const { vaultName } = ListSecretsRequestMessage.decode(request);\n        const pk = this.getPolyKey(nodePath);\n        const vault = pk.vaultManager.getVault(vaultName);\n        const secretNames = vault.listSecrets();\n        return ListSecretsResponseMessage.encode({ secretNames }).finish();\n    }\n    async createSecret(nodePath, request) {\n        const { vaultName, secretName, secretPath, secretContent } = CreateSecretRequestMessage.decode(request);\n        const pk = this.getPolyKey(nodePath);\n        const vault = pk.vaultManager.getVault(vaultName);\n        let secretBuffer;\n        if (secretPath) {\n            secretBuffer = await fs_1.default.promises.readFile(secretPath);\n        }\n        else {\n            secretBuffer = Buffer.from(secretContent);\n        }\n        await vault.addSecret(secretName, secretBuffer);\n        return CreateSecretResponseMessage.encode({ successful: true }).finish();\n    }\n    async destroySecret(nodePath, request) {\n        const { vaultName, secretName } = DestroySecretRequestMessage.decode(request);\n        const pk = this.getPolyKey(nodePath);\n        const vault = pk.vaultManager.getVault(vaultName);\n        await vault.removeSecret(secretName);\n        return DestroySecretResponseMessage.encode({ successful: true }).finish();\n    }\n    async getSecret(nodePath, request) {\n        const { vaultName, secretName } = GetSecretRequestMessage.decode(request);\n        const pk = this.getPolyKey(nodePath);\n        const vault = pk.vaultManager.getVault(vaultName);\n        const secret = Buffer.from(vault.getSecret(secretName));\n        return GetSecretResponseMessage.encode({ secret: secret }).finish();\n    }\n    async updateSecret(nodePath, request) {\n        const { vaultName, secretName, secretPath, secretContent } = UpdateSecretRequestMessage.decode(request);\n        const pk = this.getPolyKey(nodePath);\n        const vault = pk.vaultManager.getVault(vaultName);\n        let secretBuffer;\n        if (secretPath) {\n            secretBuffer = await fs_1.default.promises.readFile(secretPath);\n        }\n        else {\n            secretBuffer = Buffer.from(secretContent);\n        }\n        await vault.updateSecret(secretName, secretBuffer);\n        return UpdateSecretResponseMessage.encode({ successful: true }).finish();\n    }\n    ///////////////////////\n    // Client Connection //\n    ///////////////////////\n    static connectToAgent(getStream) {\n        const defaultStream = () => {\n            const socket = net_1.default.createConnection(PolykeyAgent.SocketPath);\n            return socket;\n        };\n        const client = new PolykeyClient_1.default(getStream !== null && getStream !== void 0 ? getStream : defaultStream);\n        return client;\n    }\n    // ===== Helper methods===== //\n    static get SocketPath() {\n        const platform = os_1.default.platform();\n        const userInfo = os_1.default.userInfo();\n        if (process_1.default.env.PK_SOCKET_PATH) {\n            return process_1.default.env.PK_SOCKET_PATH;\n        }\n        else if (platform == 'win32') {\n            return path_1.default.join('\\\\\\\\?\\\\pipe', process_1.default.cwd(), 'polykey-agent');\n        }\n        else {\n            return `/run/user/${userInfo.uid}/polykey/S.polykey-agent`;\n        }\n    }\n    static get LogPath() {\n        const platform = os_1.default.platform();\n        const userInfo = os_1.default.userInfo();\n        if (process_1.default.env.PK_LOG_PATH) {\n            return process_1.default.env.PK_LOG_PATH;\n        }\n        else if (platform == 'win32') {\n            return path_1.default.join(os_1.default.tmpdir(), 'polykey', 'log');\n        }\n        else {\n            return `/run/user/${userInfo.uid}/polykey/log`;\n        }\n    }\n    static async startAgent(daemon = false) {\n        return new Promise((resolve, reject) => {\n            try {\n                fs_1.default.rmdirSync(PolykeyAgent.LogPath, { recursive: true });\n                fs_1.default.mkdirSync(PolykeyAgent.LogPath, { recursive: true });\n                let options = {\n                    uid: process_1.default.getuid(),\n                    detached: daemon,\n                    stdio: [\n                        'ipc',\n                        fs_1.default.openSync(path_1.default.join(PolykeyAgent.LogPath, 'output.log'), 'a'),\n                        fs_1.default.openSync(path_1.default.join(PolykeyAgent.LogPath, 'error.log'), 'a'),\n                    ],\n                    silent: true,\n                };\n                const agentProcess = child_process_1.fork(PolykeyAgent.DAEMON_SCRIPT_PATH, undefined, options);\n                const pid = agentProcess.pid;\n                agentProcess.unref();\n                agentProcess.disconnect();\n                resolve(pid);\n            }\n            catch (err) {\n                reject(err);\n            }\n        });\n    }\n}\n//////////////////////\n// Agent Operations //\n//////////////////////\nPolykeyAgent.DAEMON_SCRIPT_PATH = path_1.default.join(__dirname, 'internal', 'daemon-script.js');\nexports.default = PolykeyAgent;\n","module.exports = require(\"net\");","module.exports = require(\"process\");","module.exports = require(\"child_process\");","module.exports = require(\"configstore\");"],"sourceRoot":""}